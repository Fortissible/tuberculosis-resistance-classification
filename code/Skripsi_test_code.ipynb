{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "uFUcY2AC5n59",
        "itGNRnmntCtt",
        "1pwgAqeEtF3L",
        "COoyqfjHu2Jn"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Lib\n"
      ],
      "metadata": {
        "id": "uFUcY2AC5n59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import collections\n",
        "from joblib import Parallel, delayed\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import tree\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "4MNOr3MFlNa6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RF From Scratch https://github.com/zhaoxingfeng/RandomForest"
      ],
      "metadata": {
        "id": "QaKpDQ0z487r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "49ribiZwijtS"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "@Env: Python2.7\n",
        "@Time: 2019/10/24 13:31\n",
        "@Author: zhaoxingfeng\n",
        "@Function：Random Forest（RF），随机森林二分类\n",
        "@Version: V1.2\n",
        "参考文献：\n",
        "[1] UCI. wine[DB/OL].https://archive.ics.uci.edu/ml/machine-learning-databases/wine.\n",
        "\"\"\"\n",
        "\n",
        "class Tree(object):\n",
        "    \"\"\"Define a decision tree\"\"\"\n",
        "    def __init__(self):\n",
        "        self.split_feature = None\n",
        "        self.split_value = None\n",
        "        self.leaf_value = None\n",
        "        self.tree_left = None\n",
        "        self.tree_right = None\n",
        "\n",
        "    def calc_predict_value(self, dataset):\n",
        "        \"\"\"Find the leaf node of the sample through the recursive decision tree\"\"\"\n",
        "        if self.leaf_value is not None:\n",
        "            return self.leaf_value\n",
        "        elif dataset[self.split_feature] <= self.split_value:\n",
        "            return self.tree_left.calc_predict_value(dataset)\n",
        "        else:\n",
        "            return self.tree_right.calc_predict_value(dataset)\n",
        "\n",
        "    def describe_tree(self):\n",
        "        \"\"\"\n",
        "        Print the decision tree in json form, \n",
        "        which is convenient for viewing the tree structure\n",
        "        \"\"\"\n",
        "        if not self.tree_left and not self.tree_right:\n",
        "            leaf_info = \"{leaf_value:\" + str(self.leaf_value) + \"}\"\n",
        "            return leaf_info\n",
        "        left_info = self.tree_left.describe_tree()\n",
        "        right_info = self.tree_right.describe_tree()\n",
        "        tree_structure = \"{split_feature:\" + str(self.split_feature) + \\\n",
        "                         \",split_value:\" + str(self.split_value) + \\\n",
        "                         \",left_tree:\" + left_info + \\\n",
        "                         \",right_tree:\" + right_info + \"}\"\n",
        "        return tree_structure\n",
        "\n",
        "\n",
        "class RandomForestClassifier(object):\n",
        "    def __init__(self, n_estimators=10, max_depth=-1, min_samples_split=2, min_samples_leaf=1,\n",
        "                 min_split_gain=0.0, colsample_bytree=None, subsample=0.8, random_state=None):\n",
        "        \"\"\"\n",
        "        Random Forest Parameters\n",
        "         ----------\n",
        "         n_estimators: \n",
        "              number of trees\n",
        "         max_depth: \n",
        "              tree depth, -1 means unlimited depth\n",
        "         min_samples_split: \n",
        "              The minimum number of samples required for node splitting, \n",
        "              the node terminates splitting if it is less than this value\n",
        "         min_samples_leaf: \n",
        "              The minimum sample number of leaf nodes, \n",
        "              less than this value leaves are merged\n",
        "         min_split_gain: \n",
        "              The minimum gain required for splitting, \n",
        "              less than this value the node terminates the split\n",
        "         colsample_bytree: \n",
        "              Column sampling setting, which can be [sqrt, log2]. \n",
        "              sqrt means randomly selecting sqrt(n_features) features,\n",
        "              log2 means to randomly select log(n_features) features, \n",
        "              if set to other, column sampling will not be performed\n",
        "         subsample: \n",
        "              line sampling ratio\n",
        "         random_state: \n",
        "              Random seed, after setting, \n",
        "              the n_estimators sample sets generated each time will not change, \n",
        "              ensuring that the experiment can be repeated\n",
        "        \"\"\"\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_depth = max_depth if max_depth != -1 else float('inf')\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.min_split_gain = min_split_gain\n",
        "        self.colsample_bytree = colsample_bytree\n",
        "        self.subsample = subsample\n",
        "        self.random_state = random_state\n",
        "        self.trees = None\n",
        "        self.feature_importances_ = dict()\n",
        "\n",
        "    def fit(self, dataset, targets):\n",
        "        \"\"\"Model training entry\"\"\"\n",
        "        assert targets.unique().__len__() == 2, \"There must be two class for targets!\"\n",
        "        targets = targets.to_frame(name='label')\n",
        "\n",
        "        if self.random_state:\n",
        "            random.seed(self.random_state)\n",
        "        random_state_stages = random.sample(range(self.n_estimators), self.n_estimators)\n",
        "\n",
        "        # Two column sampling methods\n",
        "        if self.colsample_bytree == \"sqrt\":\n",
        "            self.colsample_bytree = int(len(dataset.columns) ** 0.5)\n",
        "        elif self.colsample_bytree == \"log2\":\n",
        "            self.colsample_bytree = int(math.log(len(dataset.columns)))\n",
        "        else:\n",
        "            self.colsample_bytree = len(dataset.columns)\n",
        "\n",
        "        # Build multiple decision trees in parallel\n",
        "        self.trees = Parallel(n_jobs=-1, verbose=0, backend=\"threading\")(\n",
        "            delayed(self._parallel_build_trees)(dataset, targets, random_state)\n",
        "                for random_state in random_state_stages)\n",
        "        \n",
        "    def _parallel_build_trees(self, dataset, targets, random_state):\n",
        "        \"\"\"\n",
        "        bootstrap has put back sampling to \n",
        "        generate a training sample set and build a decision tree\n",
        "        \"\"\"\n",
        "        subcol_index = random.sample(dataset.columns.tolist(), self.colsample_bytree)\n",
        "        dataset_stage = dataset.sample(n=int(self.subsample * len(dataset)), replace=True, \n",
        "                                        random_state=random_state).reset_index(drop=True)\n",
        "        dataset_stage = dataset_stage.loc[:, subcol_index]\n",
        "        targets_stage = targets.sample(n=int(self.subsample * len(dataset)), replace=True, \n",
        "                                        random_state=random_state).reset_index(drop=True)\n",
        "\n",
        "        tree = self._build_single_tree(dataset_stage, targets_stage, depth=0)\n",
        "\n",
        "        # -------------- PRINT BEST NODE --------------\n",
        "        # print(tree.describe_tree())\n",
        "\n",
        "        return tree\n",
        "\n",
        "    def _build_single_tree(self, dataset, targets, depth):\n",
        "        \"\"\"Recursively build a decision tree\"\"\"\n",
        "        # If the categories of the node \n",
        "        # are all the same/the samples are less than \n",
        "        # the minimum number of samples required for splitting, \n",
        "        # select the category with the most occurrences. \n",
        "        # Termination of division/split\n",
        "        if len(targets['label'].unique()) <= 1 or dataset.__len__() <= self.min_samples_split:\n",
        "            tree = Tree()\n",
        "            tree.leaf_value = self.calc_leaf_value(targets['label'])\n",
        "            return tree\n",
        "\n",
        "        if depth < self.max_depth:\n",
        "            best_split_feature, best_split_value, best_split_gain = self.choose_best_feature(dataset, targets)\n",
        "            left_dataset, right_dataset, left_targets, right_targets = \\\n",
        "                self.split_dataset(dataset, targets, best_split_feature, best_split_value)\n",
        "\n",
        "            tree = Tree()\n",
        "            # If after the parent node is split, \n",
        "            # the left leaf node/right leaf node sample is less than \n",
        "            # the set minimum number of leaf node samples, \n",
        "            # the parent node will terminate the split\n",
        "            if left_dataset.__len__() <= self.min_samples_leaf or \\\n",
        "                    right_dataset.__len__() <= self.min_samples_leaf or \\\n",
        "                    best_split_gain <= self.min_split_gain:\n",
        "                tree.leaf_value = self.calc_leaf_value(targets['label'])\n",
        "                return tree\n",
        "            else:\n",
        "                # If this feature is used when splitting, \n",
        "                # the importance of this feature will be increased by 1\n",
        "                self.feature_importances_[best_split_feature] = \\\n",
        "                    self.feature_importances_.get(best_split_feature, 0) + 1\n",
        "\n",
        "                tree.split_feature = best_split_feature\n",
        "                tree.split_value = best_split_value\n",
        "                tree.tree_left = self._build_single_tree(left_dataset, left_targets, depth+1)\n",
        "                tree.tree_right = self._build_single_tree(right_dataset, right_targets, depth+1)\n",
        "                return tree\n",
        "        # If the depth of the tree exceeds the preset value, terminate the split\n",
        "        else:\n",
        "            tree = Tree()\n",
        "            tree.leaf_value = self.calc_leaf_value(targets['label'])\n",
        "            return tree\n",
        "\n",
        "    def choose_best_feature(self, dataset, targets):\n",
        "        \"\"\"\n",
        "        Find the best data set division method, \n",
        "        find the optimal split feature, \n",
        "        split threshold, split gain\n",
        "        \"\"\"\n",
        "        best_split_gain = 1\n",
        "        best_split_feature = None\n",
        "        best_split_value = None\n",
        "\n",
        "        for feature in dataset.columns:\n",
        "            if dataset[feature].unique().__len__() <= 100:\n",
        "                unique_values = sorted(dataset[feature].unique().tolist())\n",
        "            # If the dimension feature has too many values, \n",
        "            # select the 100th percentile value as the split threshold to be selected\n",
        "            else:\n",
        "                unique_values = np.unique([np.percentile(dataset[feature], x)\n",
        "                                           for x in np.linspace(0, 100, 100)])\n",
        "\n",
        "            # Calculate the splitting gain for the possible splitting thresholds, \n",
        "            # and select the threshold with the largest gain\n",
        "            for split_value in unique_values:\n",
        "                left_targets = targets[dataset[feature] <= split_value]\n",
        "                right_targets = targets[dataset[feature] > split_value]\n",
        "                split_gain = self.calc_gini(left_targets['label'], right_targets['label'])\n",
        "\n",
        "                if split_gain < best_split_gain:\n",
        "                    best_split_feature = feature\n",
        "                    best_split_value = split_value\n",
        "                    best_split_gain = split_gain\n",
        "        return best_split_feature, best_split_value, best_split_gain\n",
        "\n",
        "    @staticmethod\n",
        "    def calc_leaf_value(targets):\n",
        "        \"\"\"\n",
        "        Select the category with the most occurrences \n",
        "        in the sample as the value of the leaf node\n",
        "        \"\"\"\n",
        "        label_counts = collections.Counter(targets)\n",
        "        major_label = max(zip(label_counts.values(), label_counts.keys()))\n",
        "        return major_label[1]\n",
        "\n",
        "    @staticmethod\n",
        "    def calc_gini(left_targets, right_targets):\n",
        "        \"\"\"\n",
        "        The classification tree uses the Gini index as an \n",
        "        indicator to select the optimal split point\n",
        "        \"\"\"\n",
        "        split_gain = 0\n",
        "        for targets in [left_targets, right_targets]:\n",
        "            gini = 1\n",
        "            # Count how many samples are in each category, \n",
        "            # and then calculate gini\n",
        "            label_counts = collections.Counter(targets)\n",
        "            for key in label_counts:\n",
        "                prob = label_counts[key] * 1.0 / len(targets)\n",
        "                gini -= prob ** 2\n",
        "            split_gain += len(targets) * 1.0 / (len(left_targets) + len(right_targets)) * gini\n",
        "        return split_gain\n",
        "\n",
        "    @staticmethod\n",
        "    def split_dataset(dataset, targets, split_feature, split_value):\n",
        "        \"\"\"\n",
        "        Divide the sample into left and right parts according to the \n",
        "        characteristics and threshold, the left is less than or \n",
        "        equal to the threshold, and the right is greater than the threshold\n",
        "        \"\"\"\n",
        "        left_dataset = dataset[dataset[split_feature] <= split_value]\n",
        "        left_targets = targets[dataset[split_feature] <= split_value]\n",
        "        right_dataset = dataset[dataset[split_feature] > split_value]\n",
        "        right_targets = targets[dataset[split_feature] > split_value]\n",
        "        return left_dataset, right_dataset, left_targets, right_targets\n",
        "\n",
        "    def predict(self, dataset):\n",
        "        \"\"\"Input sample, predict category\"\"\"\n",
        "        res = []\n",
        "        for _, row in dataset.iterrows():\n",
        "            pred_list = []\n",
        "            # Count the prediction results of each tree, \n",
        "            # and select the result with the most occurrences \n",
        "            # as the final category\n",
        "            for tree in self.trees:\n",
        "                pred_list.append(tree.calc_predict_value(row))\n",
        "\n",
        "            pred_label_counts = collections.Counter(pred_list)\n",
        "            pred_label = max(zip(pred_label_counts.values(), pred_label_counts.keys()))\n",
        "            res.append(pred_label[1])\n",
        "        return np.array(res)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    phenotype_resistance = ['emb','inh','pza','rif']\n",
        "\n",
        "    # print(\"res_type short name list : emb, inh, pza, rif\")\n",
        "    # resistance_type = input(\"insert resistance type short name!\\n\")\n",
        "\n",
        "    # Read dataset.csv into dataframe\n",
        "    for resistance_type in phenotype_resistance:\n",
        "\n",
        "      dataFrame = pd.read_csv(f'amr_datasets_r_{resistance_type}.csv')\n",
        "\n",
        "      # Drop phen_r_inh and accession_number feature (duplicate class in dataset.csv)\n",
        "      dataFrame = dataFrame.drop(f'phen_r_{resistance_type}', axis=1)\n",
        "      dataFrame = dataFrame.drop('!accession', axis=1)\n",
        "\n",
        "      # create LabelEncoder object\n",
        "      label_encoder = LabelEncoder()\n",
        "\n",
        "      # fit and transform the categorical variable\n",
        "      dataFrame['line_age'] = label_encoder.fit_transform(dataFrame['line_age'])\n",
        "\n",
        "\n",
        "      # df = pd.read_csv(\"wine.txt\")\n",
        "      # df = df[df['label'].isin([1, 2])].sample(frac=1, random_state=66).reset_index(drop=True)\n",
        "      # print(\"df\\n\",df)\n",
        "\n",
        "      opt_n_estimators = [5,10,25,50,100]\n",
        "      opt_max_depth = [10,25,50,75,100]\n",
        "      opt_random_state = [2,8,16,32,64]\n",
        "      opt_min_samples_split = [10,20,30,40,50]\n",
        "\n",
        "      arr_acc_train = []\n",
        "      arr_acc_test = []\n",
        "\n",
        "      for p1,p2,p3,p4 in zip(\n",
        "          opt_n_estimators, \n",
        "          opt_max_depth, \n",
        "          opt_random_state, \n",
        "          opt_min_samples_split\n",
        "          ):\n",
        "\n",
        "        clf = RandomForestClassifier(n_estimators=p1,\n",
        "                                    max_depth=p2,\n",
        "                                    min_samples_split=p4,\n",
        "                                    min_samples_leaf=2,\n",
        "                                    min_split_gain=0.0,\n",
        "                                    colsample_bytree=\"sqrt\",\n",
        "                                    subsample=0.8,\n",
        "                                    random_state=p3)\n",
        "\n",
        "        x, y = dataFrame.iloc[:, :-1], dataFrame.iloc[:, -1]\n",
        "\n",
        "        x_train, x_test, y_train, y_test = train_test_split(\n",
        "            x, y, test_size=0.3, random_state=random.randint(1, 25)\n",
        "        )\n",
        "\n",
        "        clf.fit(x_train, y_train)\n",
        "\n",
        "        from sklearn import metrics\n",
        "        print(\"-------MODEL\",resistance_type,\"with Parameter:\",p1,p2,p3,p4,\"-------\")\n",
        "        print(metrics.accuracy_score(y_train, clf.predict(x_train)))\n",
        "        print(metrics.accuracy_score(y_test, clf.predict(x_test)))\n",
        "\n",
        "        arr_acc_train.append(metrics.accuracy_score(y_train, clf.predict(x_train)))\n",
        "        arr_acc_test.append(metrics.accuracy_score(y_test, clf.predict(x_test)))\n",
        "      print(\"-------MODEL\",resistance_type,\"-------\")\n",
        "      print(resistance_type,\"model train_acc_result:\",arr_acc_train)\n",
        "      print(resistance_type,\"model test_acc_result:\",arr_acc_test)\n",
        "      print(resistance_type,\"model avg_train_acc:\", np.average(np.array(arr_acc_train)))\n",
        "      print(resistance_type,\"model avg_test_acc:\", np.average(np.array(arr_acc_test)))"
      ],
      "metadata": {
        "id": "XDIofusQlAc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45097ef7-534a-4a55-b37d-1a41fa1048b9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------MODEL emb with Parameter: 5 10 2 10 -------\n",
            "0.743801652892562\n",
            "0.5853658536585366\n",
            "-------MODEL emb with Parameter: 10 25 8 20 -------\n",
            "0.7603305785123967\n",
            "0.5853658536585366\n",
            "-------MODEL emb with Parameter: 25 50 16 30 -------\n",
            "0.7520661157024794\n",
            "0.5853658536585366\n",
            "-------MODEL emb with Parameter: 50 75 32 40 -------\n",
            "0.7520661157024794\n",
            "0.5853658536585366\n",
            "-------MODEL emb with Parameter: 100 100 64 50 -------\n",
            "0.7520661157024794\n",
            "0.5853658536585366\n",
            "-------MODEL emb -------\n",
            "emb model train_acc_result: [0.743801652892562, 0.7603305785123967, 0.7520661157024794, 0.7520661157024794, 0.7520661157024794]\n",
            "emb model test_acc_result: [0.5853658536585366, 0.5853658536585366, 0.5853658536585366, 0.5853658536585366, 0.5853658536585366]\n",
            "emb model avg_train_acc: 0.7520661157024793\n",
            "emb model avg_test_acc: 0.5853658536585366\n",
            "-------MODEL inh with Parameter: 5 10 2 10 -------\n",
            "0.6585365853658537\n",
            "0.6428571428571429\n",
            "-------MODEL inh with Parameter: 10 25 8 20 -------\n",
            "0.6910569105691057\n",
            "0.6428571428571429\n",
            "-------MODEL inh with Parameter: 25 50 16 30 -------\n",
            "0.7317073170731707\n",
            "0.6904761904761905\n",
            "-------MODEL inh with Parameter: 50 75 32 40 -------\n",
            "0.7073170731707317\n",
            "0.6666666666666666\n",
            "-------MODEL inh with Parameter: 100 100 64 50 -------\n",
            "0.6666666666666666\n",
            "0.6428571428571429\n",
            "-------MODEL inh -------\n",
            "inh model train_acc_result: [0.6585365853658537, 0.6910569105691057, 0.7317073170731707, 0.7073170731707317, 0.6666666666666666]\n",
            "inh model test_acc_result: [0.6428571428571429, 0.6428571428571429, 0.6904761904761905, 0.6666666666666666, 0.6428571428571429]\n",
            "inh model avg_train_acc: 0.6910569105691056\n",
            "inh model avg_test_acc: 0.6571428571428571\n",
            "-------MODEL pza with Parameter: 5 10 2 10 -------\n",
            "0.9338842975206612\n",
            "0.8780487804878049\n",
            "-------MODEL pza with Parameter: 10 25 8 20 -------\n",
            "0.9338842975206612\n",
            "0.8780487804878049\n",
            "-------MODEL pza with Parameter: 25 50 16 30 -------\n",
            "0.9338842975206612\n",
            "0.8780487804878049\n",
            "-------MODEL pza with Parameter: 50 75 32 40 -------\n",
            "0.9338842975206612\n",
            "0.8780487804878049\n",
            "-------MODEL pza with Parameter: 100 100 64 50 -------\n",
            "0.9338842975206612\n",
            "0.8780487804878049\n",
            "-------MODEL pza -------\n",
            "pza model train_acc_result: [0.9338842975206612, 0.9338842975206612, 0.9338842975206612, 0.9338842975206612, 0.9338842975206612]\n",
            "pza model test_acc_result: [0.8780487804878049, 0.8780487804878049, 0.8780487804878049, 0.8780487804878049, 0.8780487804878049]\n",
            "pza model avg_train_acc: 0.9338842975206612\n",
            "pza model avg_test_acc: 0.878048780487805\n",
            "-------MODEL rif with Parameter: 5 10 2 10 -------\n",
            "0.860655737704918\n",
            "0.7560975609756098\n",
            "-------MODEL rif with Parameter: 10 25 8 20 -------\n",
            "0.860655737704918\n",
            "0.7560975609756098\n",
            "-------MODEL rif with Parameter: 25 50 16 30 -------\n",
            "0.860655737704918\n",
            "0.7560975609756098\n",
            "-------MODEL rif with Parameter: 50 75 32 40 -------\n",
            "0.860655737704918\n",
            "0.7560975609756098\n",
            "-------MODEL rif with Parameter: 100 100 64 50 -------\n",
            "0.860655737704918\n",
            "0.7560975609756098\n",
            "-------MODEL rif -------\n",
            "rif model train_acc_result: [0.860655737704918, 0.860655737704918, 0.860655737704918, 0.860655737704918, 0.860655737704918]\n",
            "rif model test_acc_result: [0.7560975609756098, 0.7560975609756098, 0.7560975609756098, 0.7560975609756098, 0.7560975609756098]\n",
            "rif model avg_train_acc: 0.860655737704918\n",
            "rif model avg_test_acc: 0.7560975609756098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree from https://github.com/harrypnh/random-forest-from-scratch"
      ],
      "metadata": {
        "id": "itGNRnmntCtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainTestSplit(dataFrame, testSize):\n",
        "    if isinstance(testSize, float):\n",
        "        testSize = round(testSize * len(dataFrame))\n",
        "    indices = dataFrame.index.tolist()\n",
        "    testIndices = random.sample(population = indices, k = testSize)\n",
        "    dataFrameTest = dataFrame.loc[testIndices]\n",
        "    dataFrameTrain = dataFrame.drop(testIndices)\n",
        "    return dataFrameTrain, dataFrameTest\n",
        "\n",
        "def checkPurity(data):\n",
        "    if len(np.unique(data[:, -1])) == 1:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def classifyData(data):\n",
        "    uniqueClasses, uniqueClassesCounts = np.unique(data[:, -1], return_counts = True)\n",
        "    return uniqueClasses[uniqueClassesCounts.argmax()]\n",
        "\n",
        "def getPotentialSplits(data, randomAttributes):\n",
        "    potentialSplits = {}\n",
        "    _, columns = data.shape\n",
        "    columnsIndices = list(range(columns - 1))\n",
        "    if randomAttributes != None  and len(randomAttributes) <= len(columnsIndices):\n",
        "        columnsIndices = randomAttributes\n",
        "    for column in columnsIndices:\n",
        "        values = data[:, column]\n",
        "        uniqueValues = np.unique(values)\n",
        "        if len(uniqueValues) == 1:\n",
        "            potentialSplits[column] = uniqueValues\n",
        "        else:\n",
        "            potentialSplits[column] = []\n",
        "            for i in range(len(uniqueValues)):\n",
        "                if i != 0:\n",
        "                    currentValue = uniqueValues[i]\n",
        "                    previousValue = uniqueValues[i - 1]\n",
        "                    potentialSplits[column].append((currentValue + previousValue) / 2)\n",
        "    return potentialSplits\n",
        "\n",
        "def splitData(data, splitColumn, splitValue):\n",
        "    splitColumnValues = data[:, splitColumn]\n",
        "    return data[splitColumnValues <= splitValue], data[splitColumnValues > splitValue]\n",
        "\n",
        "def calculateEntropy(data):\n",
        "    _, uniqueClassesCounts = np.unique(data[:, -1], return_counts = True)\n",
        "    probabilities = uniqueClassesCounts / uniqueClassesCounts.sum()\n",
        "    return sum(probabilities * -np.log2(probabilities))\n",
        "\n",
        "def calculateOverallEntropy(dataBelow, dataAbove):\n",
        "    pDataBelow = len(dataBelow) / (len(dataBelow) + len(dataAbove))\n",
        "    pDataAbove = len(dataAbove) / (len(dataBelow) + len(dataAbove))\n",
        "    return pDataBelow * calculateEntropy(dataBelow) + pDataAbove * calculateEntropy(dataAbove)\n",
        "\n",
        "def determineBestSplit(data, potentialSplits, randomSplits = None):\n",
        "    overallEntropy = 9999\n",
        "    bestSplitColumn = 0\n",
        "    bestSplitValue = 0\n",
        "    if randomSplits == None:\n",
        "        for splitColumn in potentialSplits:\n",
        "            for splitValue in potentialSplits[splitColumn]:\n",
        "                dataBelow, dataAbove = splitData(data, splitColumn, splitValue)\n",
        "                currentOverallEntropy = calculateOverallEntropy(dataBelow, dataAbove)\n",
        "                if currentOverallEntropy <= overallEntropy:\n",
        "                    overallEntropy = currentOverallEntropy\n",
        "                    bestSplitColumn = splitColumn\n",
        "                    bestSplitValue = splitValue\n",
        "    else:\n",
        "        for i in range(randomSplits):\n",
        "            randomSplitColumn = random.choice(list(potentialSplits))\n",
        "            randomSplitValue = random.choice(potentialSplits[randomSplitColumn])\n",
        "            dataBelow, dataAbove = splitData(data, randomSplitColumn, randomSplitValue)\n",
        "            currentOverallEntropy = calculateOverallEntropy(dataBelow, dataAbove)\n",
        "            if currentOverallEntropy <= overallEntropy:\n",
        "                overallEntropy = currentOverallEntropy\n",
        "                bestSplitColumn = randomSplitColumn\n",
        "                bestSplitValue = randomSplitValue\n",
        "    return bestSplitColumn, bestSplitValue\n",
        "\n",
        "def classifySample(sample, decisionTree):\n",
        "    if not isinstance(decisionTree, dict):\n",
        "        return decisionTree\n",
        "    question = list(decisionTree.keys())[0]\n",
        "    attribute, value = question.split(\" <= \")\n",
        "    if sample[attribute] <= float(value):\n",
        "        answer = decisionTree[question][0]\n",
        "    else:\n",
        "        answer = decisionTree[question][1]\n",
        "    return classifySample(sample, answer)\n",
        "\n",
        "def calculateAccuracy(predictedResults, category):\n",
        "    resultCorrect = predictedResults == category\n",
        "    return resultCorrect.mean()"
      ],
      "metadata": {
        "id": "hUZc3vWas9Gf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def buildDecisionTree(dataFrame, currentDepth = 0, minSampleSize = 2, maxDepth = 1000, randomAttributes = None, randomSplits = None):\n",
        "    if currentDepth == 0:\n",
        "        global COLUMN_HEADERS\n",
        "        COLUMN_HEADERS = dataFrame.columns\n",
        "        data = dataFrame.values\n",
        "        if randomAttributes != None and randomAttributes <= len(COLUMN_HEADERS) - 1:\n",
        "            randomAttributes = random.sample(population = list(range(len(COLUMN_HEADERS) - 1)), k = randomAttributes)\n",
        "        else:\n",
        "            randomAttributes = None\n",
        "    else:\n",
        "        data = dataFrame\n",
        "    if checkPurity(data) or len(data) < minSampleSize or currentDepth == maxDepth:\n",
        "        return classifyData(data)\n",
        "    else:\n",
        "        currentDepth += 1\n",
        "        potentialSplits = getPotentialSplits(data, randomAttributes)\n",
        "        splitColumn, splitValue = determineBestSplit(data, potentialSplits, randomSplits)\n",
        "        dataBelow, dataAbove = splitData(data, splitColumn, splitValue)\n",
        "        if len(dataBelow) == 0 or len(dataAbove) == 0:\n",
        "            return classifyData(data)\n",
        "        else:\n",
        "            question = str(COLUMN_HEADERS[splitColumn]) + \" <= \" + str(splitValue)\n",
        "            decisionSubTree = {question: []}\n",
        "            yesAnswer = buildDecisionTree(dataBelow, currentDepth, minSampleSize, maxDepth, randomAttributes, randomSplits)\n",
        "            noAnswer = buildDecisionTree(dataAbove, currentDepth, minSampleSize, maxDepth, randomAttributes, randomSplits)\n",
        "            if yesAnswer == noAnswer:\n",
        "                decisionSubTree = yesAnswer\n",
        "            else:\n",
        "                decisionSubTree[question].append(yesAnswer)\n",
        "                decisionSubTree[question].append(noAnswer)\n",
        "            return decisionSubTree\n",
        "\n",
        "def decisionTreePredictions(dataFrame, decisionTree):\n",
        "    predictions = dataFrame.apply(classifySample, axis = 1, args = (decisionTree,))\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "27QXSqPPtg0v"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest from https://github.com/harrypnh/random-forest-from-scratch"
      ],
      "metadata": {
        "id": "1pwgAqeEtF3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainTestSplit(dataFrame, testSize):\n",
        "    if isinstance(testSize, float):\n",
        "        testSize = round(testSize * len(dataFrame))\n",
        "    indices = dataFrame.index.tolist()\n",
        "    testIndices = random.sample(population = indices, k = testSize)\n",
        "    dataFrameTest = dataFrame.loc[testIndices]\n",
        "    dataFrameTrain = dataFrame.drop(testIndices)\n",
        "    return dataFrameTrain, dataFrameTest\n",
        "\n",
        "def bootstrapSample(dataFrame, bootstrapSize):\n",
        "    randomIndices = np.random.randint(low = 0, high = len(dataFrame), size = bootstrapSize)\n",
        "    return dataFrame.iloc[randomIndices]\n",
        "\n",
        "def createRandomForest(dataFrame, bootstrapSize, randomAttributes, randomSplits, forestSize = 20, treeMaxDepth = 1000):\n",
        "    forest = []\n",
        "    for i in range(forestSize):\n",
        "        bootstrappedDataFrame = bootstrapSample(dataFrame, bootstrapSize)\n",
        "        decisionTree = buildDecisionTree(bootstrappedDataFrame, maxDepth = treeMaxDepth, randomAttributes = randomAttributes, randomSplits = randomSplits)\n",
        "        forest.append(decisionTree)\n",
        "    return forest\n",
        "\n",
        "def randomForestPredictions(dataFrame, randomForest):\n",
        "    predictions = {}\n",
        "    for i in range(len(randomForest)):\n",
        "        column = \"decision tree \" + str(i)\n",
        "        predictions[column] = decisionTreePredictions(dataFrame, randomForest[i])\n",
        "    predictions = pd.DataFrame(predictions)\n",
        "    return predictions.mode(axis = 1)[0]\n",
        "\n",
        "def calculateAccuracy(predictedResults, category):\n",
        "    resultCorrect = predictedResults == category\n",
        "    return resultCorrect.mean()"
      ],
      "metadata": {
        "id": "bdHEqUT0syUX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test using amr data"
      ],
      "metadata": {
        "id": "COoyqfjHu2Jn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"res_type short name list : emb, inh, pza, rif\")\n",
        "resistance_type = input(\"insert resistance type short name!\\n\")\n",
        "\n",
        "# Read dataset.csv into dataframe\n",
        "dataFrame = pd.read_csv(f'amr_datasets_r_{resistance_type}.csv')\n",
        "\n",
        "# Drop phen_r_inh and accession_number feature (duplicate class in dataset.csv)\n",
        "dataFrame = dataFrame.drop(f'phen_r_{resistance_type}', axis=1)\n",
        "dataFrame = dataFrame.drop('!accession', axis=1)\n",
        "\n",
        "# create LabelEncoder object\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# fit and transform the categorical variable\n",
        "dataFrame['line_age'] = label_encoder.fit_transform(dataFrame['line_age'])\n",
        "\n",
        "print(dataFrame)\n",
        "dataFrameTrain, dataFrameTest = trainTestSplit(dataFrame, testSize = 0.4)\n",
        "\n",
        "print(\"Random Forest - Breast Cancer Dataset\")\n",
        "print(\"  Maximum bootstrap size (n) is {}\".format(dataFrameTrain.shape[0]))\n",
        "print(\"  Maximum random subspace size (d) is {}\".format(dataFrameTrain.shape[1] - 1))\n",
        "\n",
        "print(\"\\n  Change n, keep other parameters\")\n",
        "for i in range(10, dataFrameTrain.shape[0] + 1, 50):\n",
        "    startTime = time.time()\n",
        "    randomForest = createRandomForest(dataFrameTrain, bootstrapSize = i, randomAttributes = 10, randomSplits = 50, forestSize = 30, treeMaxDepth = 3)\n",
        "    buildingTime = time.time() - startTime\n",
        "    randomForestTestResults = randomForestPredictions(dataFrameTest, randomForest)\n",
        "    accuracyTest = calculateAccuracy(randomForestTestResults, dataFrameTest.iloc[:, -1]) * 100\n",
        "    randomForestTrainResults = randomForestPredictions(dataFrameTrain, randomForest)\n",
        "    accuracyTrain = calculateAccuracy(randomForestTrainResults, dataFrameTrain.iloc[:, -1]) * 100\n",
        "    print(\"  n = {}, d = {}, s = {}, k = {}, maxDepth = {}:\".format(i, 10, 50, 30, 3))\n",
        "    print(\"    accTest = {0:.2f}%, \".format(accuracyTest), end = \"\")\n",
        "    print(\"accTrain = {0:.2f}%, \".format(accuracyTrain), end = \"\")\n",
        "    print(\"buildTime = {0:.2f}s\".format(buildingTime), end = \"\\n\")\n",
        "\n",
        "# print(\"\\n  Change d, keep other parameters\")\n",
        "# for i in range(10, dataFrameTrain.shape[1], 2):\n",
        "#     startTime = time.time()\n",
        "#     randomForest = createRandomForest(dataFrameTrain, bootstrapSize = 60, randomAttributes = i, randomSplits = 50, forestSize = 30, treeMaxDepth = 3)\n",
        "#     buildingTime = time.time() - startTime\n",
        "#     randomForestTestResults = randomForestPredictions(dataFrameTest, randomForest)\n",
        "#     accuracyTest = calculateAccuracy(randomForestTestResults, dataFrameTest.iloc[:, -1]) * 100\n",
        "#     randomForestTrainResults = randomForestPredictions(dataFrameTrain, randomForest)\n",
        "#     accuracyTrain = calculateAccuracy(randomForestTrainResults, dataFrameTrain.iloc[:, -1]) * 100\n",
        "#     print(\"  n = {}, d = {}, s = {}, k = {}, maxDepth = {}:\".format(60, i, 50, 30, 3))\n",
        "#     print(\"    accTest = {0:.2f}%, \".format(accuracyTest), end = \"\")\n",
        "#     print(\"accTrain = {0:.2f}%, \".format(accuracyTrain), end = \"\")\n",
        "#     print(\"buildTime = {0:.2f}s\".format(buildingTime), end = \"\\n\")\n",
        "\n",
        "print(\"\\n  Change s, keep other parameters\")\n",
        "for i in range(10, 100 + 1, 10):\n",
        "    startTime = time.time()\n",
        "    randomForest = createRandomForest(dataFrameTrain, bootstrapSize = 60, randomAttributes = 10, randomSplits = i, forestSize = 30, treeMaxDepth = 3)\n",
        "    buildingTime = time.time() - startTime\n",
        "    randomForestTestResults = randomForestPredictions(dataFrameTest, randomForest)\n",
        "    accuracyTest = calculateAccuracy(randomForestTestResults, dataFrameTest.iloc[:, -1]) * 100\n",
        "    randomForestTrainResults = randomForestPredictions(dataFrameTrain, randomForest)\n",
        "    accuracyTrain = calculateAccuracy(randomForestTrainResults, dataFrameTrain.iloc[:, -1]) * 100\n",
        "    print(\"  n = {}, d = {}, s = {}, k = {}, maxDepth = {}:\".format(60, 10, i, 30, 3))\n",
        "    print(\"    accTest = {0:.2f}%, \".format(accuracyTest), end = \"\")\n",
        "    print(\"accTrain = {0:.2f}%, \".format(accuracyTrain), end = \"\")\n",
        "    print(\"buildTime = {0:.2f}s\".format(buildingTime), end = \"\\n\")\n",
        "\n",
        "print(\"\\n  Change k, keep other parameters\")\n",
        "for i in range(10, 100 + 1, 10):\n",
        "    startTime = time.time()\n",
        "    randomForest = createRandomForest(dataFrameTrain, bootstrapSize = 60, randomAttributes = 10, randomSplits = 50, forestSize = i, treeMaxDepth = 3)\n",
        "    buildingTime = time.time() - startTime\n",
        "    randomForestTestResults = randomForestPredictions(dataFrameTest, randomForest)\n",
        "    accuracyTest = calculateAccuracy(randomForestTestResults, dataFrameTest.iloc[:, -1]) * 100\n",
        "    randomForestTrainResults = randomForestPredictions(dataFrameTrain, randomForest)\n",
        "    accuracyTrain = calculateAccuracy(randomForestTrainResults, dataFrameTrain.iloc[:, -1]) * 100\n",
        "    print(\"  n = {}, d = {}, s = {}, k = {}, maxDepth = {}:\".format(60, 10, 50, i, 3))\n",
        "    print(\"    accTest = {0:.2f}%, \".format(accuracyTest), end = \"\")\n",
        "    print(\"accTrain = {0:.2f}%, \".format(accuracyTrain), end = \"\")\n",
        "    print(\"buildTime = {0:.2f}s\".format(buildingTime), end = \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "412l_dA0s5Ig",
        "outputId": "5e734f69-2b12-4538-ffeb-a5487a4484b5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "res_type short name list : emb, inh, pza, rif\n",
            "insert resistance type short name!\n",
            "emb\n",
            "     AAC_2___Ic_.  Erm_37__.  Mycobacterium_tuberculosis_Rv1258c_1_.  \\\n",
            "0               0          0                                       1   \n",
            "1               0          0                                       1   \n",
            "2               0          0                                       0   \n",
            "3               0          0                                       0   \n",
            "4               0          0                                       0   \n",
            "..            ...        ...                                     ...   \n",
            "157             0          0                                       1   \n",
            "158             0          0                                       1   \n",
            "159             0          0                                       1   \n",
            "160             0          0                                       0   \n",
            "161             0          0                                       1   \n",
            "\n",
            "     Mycobacterium_tuberculosis_Rv1258c_1_S292L  \\\n",
            "0                                             0   \n",
            "1                                             0   \n",
            "2                                             1   \n",
            "3                                             1   \n",
            "4                                             1   \n",
            "..                                          ...   \n",
            "157                                           0   \n",
            "158                                           0   \n",
            "159                                           0   \n",
            "160                                           1   \n",
            "161                                           0   \n",
            "\n",
            "     Mycobacterium_tuberculosis_Rv1258c_1_V219A  \\\n",
            "0                                             0   \n",
            "1                                             0   \n",
            "2                                             1   \n",
            "3                                             1   \n",
            "4                                             1   \n",
            "..                                          ...   \n",
            "157                                           0   \n",
            "158                                           0   \n",
            "159                                           0   \n",
            "160                                           1   \n",
            "161                                           0   \n",
            "\n",
            "     Mycobacterium_tuberculosis_ndh_.  Mycobacterium_tuberculosis_ndh_A300P  \\\n",
            "0                                   0                                     1   \n",
            "1                                   0                                     1   \n",
            "2                                   0                                     1   \n",
            "3                                   1                                     0   \n",
            "4                                   1                                     1   \n",
            "..                                ...                                   ...   \n",
            "157                                 0                                     1   \n",
            "158                                 0                                     1   \n",
            "159                                 0                                     1   \n",
            "160                                 0                                     1   \n",
            "161                                 0                                     1   \n",
            "\n",
            "     Mycobacterium_tuberculosis_ndh_G313R  \\\n",
            "0                                       1   \n",
            "1                                       1   \n",
            "2                                       1   \n",
            "3                                       0   \n",
            "4                                       1   \n",
            "..                                    ...   \n",
            "157                                     1   \n",
            "158                                     1   \n",
            "159                                     1   \n",
            "160                                     1   \n",
            "161                                     1   \n",
            "\n",
            "     Mycobacterium_tuberculosis_ndh_G339A  \\\n",
            "0                                       1   \n",
            "1                                       1   \n",
            "2                                       1   \n",
            "3                                       0   \n",
            "4                                       1   \n",
            "..                                    ...   \n",
            "157                                     1   \n",
            "158                                     1   \n",
            "159                                     1   \n",
            "160                                     1   \n",
            "161                                     1   \n",
            "\n",
            "     Mycobacterium_tuberculosis_ndh_L50V  ...  tlyA_F185L  tlyA_K69E  \\\n",
            "0                                      1  ...           1          1   \n",
            "1                                      1  ...           1          1   \n",
            "2                                      1  ...           1          1   \n",
            "3                                      1  ...           1          1   \n",
            "4                                      1  ...           1          1   \n",
            "..                                   ...  ...         ...        ...   \n",
            "157                                    1  ...           1          1   \n",
            "158                                    1  ...           1          1   \n",
            "159                                    1  ...           1          1   \n",
            "160                                    1  ...           1          1   \n",
            "161                                    1  ...           1          1   \n",
            "\n",
            "     tlyA_L118P  tlyA_L150P  tlyA_N236K  tlyA_P183L  tlyA_R14W  tlyA_V128E  \\\n",
            "0             1           1           1           1          1           1   \n",
            "1             1           1           1           1          1           1   \n",
            "2             1           1           1           1          1           1   \n",
            "3             1           1           1           1          1           1   \n",
            "4             1           1           1           1          1           1   \n",
            "..          ...         ...         ...         ...        ...         ...   \n",
            "157           1           1           1           1          1           1   \n",
            "158           1           1           1           1          1           1   \n",
            "159           1           1           1           1          1           1   \n",
            "160           1           1           1           1          1           1   \n",
            "161           1           1           1           1          1           1   \n",
            "\n",
            "     line_age  phen_emb  \n",
            "0           1         1  \n",
            "1           1         1  \n",
            "2           3         1  \n",
            "3           3         1  \n",
            "4           3         1  \n",
            "..        ...       ...  \n",
            "157         1         1  \n",
            "158         1         1  \n",
            "159         1         1  \n",
            "160         0         1  \n",
            "161         1         1  \n",
            "\n",
            "[162 rows x 435 columns]\n",
            "Random Forest - Breast Cancer Dataset\n",
            "  Maximum bootstrap size (n) is 97\n",
            "  Maximum random subspace size (d) is 434\n",
            "\n",
            "  Change n, keep other parameters\n",
            "  n = 10, d = 10, s = 50, k = 30, maxDepth = 3:\n",
            "    accTest = 67.69%, accTrain = 72.16%, buildTime = 0.28s\n",
            "  n = 60, d = 10, s = 50, k = 30, maxDepth = 3:\n",
            "    accTest = 67.69%, accTrain = 74.23%, buildTime = 0.55s\n",
            "\n",
            "  Change s, keep other parameters\n",
            "  n = 60, d = 10, s = 10, k = 30, maxDepth = 3:\n",
            "    accTest = 67.69%, accTrain = 73.20%, buildTime = 0.12s\n",
            "  n = 60, d = 10, s = 20, k = 30, maxDepth = 3:\n",
            "    accTest = 67.69%, accTrain = 75.26%, buildTime = 0.44s\n",
            "  n = 60, d = 10, s = 30, k = 30, maxDepth = 3:\n",
            "    accTest = 67.69%, accTrain = 75.26%, buildTime = 0.98s\n",
            "  n = 60, d = 10, s = 40, k = 30, maxDepth = 3:\n",
            "    accTest = 67.69%, accTrain = 74.23%, buildTime = 1.10s\n",
            "  n = 60, d = 10, s = 50, k = 30, maxDepth = 3:\n",
            "    accTest = 67.69%, accTrain = 74.23%, buildTime = 0.54s\n",
            "  n = 60, d = 10, s = 60, k = 30, maxDepth = 3:\n",
            "    accTest = 67.69%, accTrain = 74.23%, buildTime = 0.63s\n",
            "  n = 60, d = 10, s = 70, k = 30, maxDepth = 3:\n",
            "    accTest = 67.69%, accTrain = 75.26%, buildTime = 0.79s\n",
            "  n = 60, d = 10, s = 80, k = 30, maxDepth = 3:\n",
            "    accTest = 67.69%, accTrain = 74.23%, buildTime = 0.77s\n",
            "  n = 60, d = 10, s = 90, k = 30, maxDepth = 3:\n",
            "    accTest = 67.69%, accTrain = 75.26%, buildTime = 1.13s\n",
            "  n = 60, d = 10, s = 100, k = 30, maxDepth = 3:\n",
            "    accTest = 67.69%, accTrain = 74.23%, buildTime = 1.72s\n",
            "\n",
            "  Change k, keep other parameters\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-16554459a383>\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mstartTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mrandomForest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateRandomForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataFrameTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbootstrapSize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomAttributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomSplits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforestSize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreeMaxDepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mbuildingTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstartTime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mrandomForestTestResults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomForestPredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataFrameTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomForest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-22ace86db087>\u001b[0m in \u001b[0;36mcreateRandomForest\u001b[0;34m(dataFrame, bootstrapSize, randomAttributes, randomSplits, forestSize, treeMaxDepth)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforestSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mbootstrappedDataFrame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbootstrapSample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbootstrapSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mdecisionTree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuildDecisionTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbootstrappedDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxDepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtreeMaxDepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomAttributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomAttributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomSplits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomSplits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecisionTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-4ad84c08ac66>\u001b[0m in \u001b[0;36mbuildDecisionTree\u001b[0;34m(dataFrame, currentDepth, minSampleSize, maxDepth, randomAttributes, randomSplits)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOLUMN_HEADERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplitColumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" <= \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplitValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mdecisionSubTree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0myesAnswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuildDecisionTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataBelow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrentDepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminSampleSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxDepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomAttributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomSplits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mnoAnswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuildDecisionTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataAbove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrentDepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminSampleSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxDepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomAttributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomSplits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0myesAnswer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnoAnswer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-4ad84c08ac66>\u001b[0m in \u001b[0;36mbuildDecisionTree\u001b[0;34m(dataFrame, currentDepth, minSampleSize, maxDepth, randomAttributes, randomSplits)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mdecisionSubTree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0myesAnswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuildDecisionTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataBelow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrentDepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminSampleSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxDepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomAttributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomSplits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mnoAnswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuildDecisionTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataAbove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrentDepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminSampleSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxDepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomAttributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomSplits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0myesAnswer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnoAnswer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mdecisionSubTree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myesAnswer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-4ad84c08ac66>\u001b[0m in \u001b[0;36mbuildDecisionTree\u001b[0;34m(dataFrame, currentDepth, minSampleSize, maxDepth, randomAttributes, randomSplits)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mcurrentDepth\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpotentialSplits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetPotentialSplits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomAttributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0msplitColumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplitValue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetermineBestSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpotentialSplits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomSplits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mdataBelow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataAbove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplitColumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplitValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataBelow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataAbove\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-31a357b0c38b>\u001b[0m in \u001b[0;36mdetermineBestSplit\u001b[0;34m(data, potentialSplits, randomSplits)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mrandomSplitColumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpotentialSplits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mrandomSplitValue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpotentialSplits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandomSplitColumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mdataBelow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataAbove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomSplitColumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomSplitValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mcurrentOverallEntropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculateOverallEntropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataBelow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataAbove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcurrentOverallEntropy\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0moverallEntropy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-31a357b0c38b>\u001b[0m in \u001b[0;36msplitData\u001b[0;34m(data, splitColumn, splitValue)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msplitData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplitColumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplitValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0msplitColumnValues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplitColumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplitColumnValues\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0msplitValue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplitColumnValues\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0msplitValue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculateEntropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print all the index numbers of the DataFrame\n",
        "print(sorted(dataFrame.index.tolist()))\n",
        "print(label_encoder.classes_)\n",
        "print(label_encoder.transform(label_encoder.classes_))\n",
        "print(\"\\n=======Train=======\\n\")\n",
        "print(sorted(dataFrameTrain.index.tolist()))\n",
        "# count the number of data points for each class\n",
        "class_counts = dataFrameTrain[f'phen_{resistance_type}'].value_counts()\n",
        "# print the class counts\n",
        "print(class_counts)\n",
        "\n",
        "print(\"\\n=========Test=========\\n\")\n",
        "print(sorted(dataFrameTest.index.tolist()))\n",
        "# count the number of data points for each class\n",
        "class_counts = dataFrameTest[f'phen_{resistance_type}'].value_counts()\n",
        "# print the class counts\n",
        "print(class_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WZPh8LbwNeq",
        "outputId": "396c4037-0c01-4ed6-c33d-7343589d4b40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162]\n",
            "['1' '2' '3' '4' '4 (Cameroon)' '4 (Haarlem)' '4 (LAM)' '4 (S-type)'\n",
            " '4 (Tur)' '4 (Uganda)' '4 (Ural)' '4 (X-type)' '6' 'M. bovis' 'M. orygis'\n",
            " nan]\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "\n",
            "=======Train=======\n",
            "\n",
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 21, 22, 23, 24, 28, 31, 33, 34, 35, 36, 37, 38, 40, 41, 47, 50, 52, 55, 56, 57, 58, 59, 60, 62, 63, 67, 68, 70, 72, 73, 74, 76, 78, 79, 80, 83, 84, 86, 88, 89, 90, 91, 92, 94, 97, 99, 100, 102, 103, 104, 105, 108, 109, 112, 115, 116, 117, 118, 120, 121, 122, 124, 126, 127, 128, 130, 131, 133, 134, 136, 137, 138, 140, 144, 145, 147, 148, 149, 151, 152, 156, 157, 158, 160]\n",
            "0    80\n",
            "1    18\n",
            "Name: phen_rif, dtype: int64\n",
            "\n",
            "=========Test=========\n",
            "\n",
            "[0, 11, 14, 15, 16, 17, 20, 25, 26, 27, 29, 30, 32, 39, 42, 43, 44, 45, 46, 48, 49, 51, 53, 54, 61, 64, 65, 66, 69, 71, 75, 77, 81, 82, 85, 87, 93, 95, 96, 98, 101, 106, 107, 110, 111, 113, 114, 119, 123, 125, 129, 132, 135, 139, 141, 142, 143, 146, 150, 153, 154, 155, 159, 161, 162]\n",
            "0    56\n",
            "1     9\n",
            "Name: phen_rif, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}