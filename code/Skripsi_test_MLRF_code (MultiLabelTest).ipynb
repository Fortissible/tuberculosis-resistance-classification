{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "QDfgbiR2CcQe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import collections\n",
        "from joblib import Parallel, delayed\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import tree\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import tree as sk_tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "ho5uyZdSCysy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0279e5fa-0bf2-47af-e0e2-47e8481b104d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     AAC_2___Ic_.  Erm_37__.  Mycobacterium_tuberculosis_Rv1258c_1_.  \\\n",
            "0               0          0                                       1   \n",
            "1               0          0                                       1   \n",
            "2               0          0                                       0   \n",
            "3               0          0                                       0   \n",
            "4               0          0                                       0   \n",
            "..            ...        ...                                     ...   \n",
            "157             0          0                                       0   \n",
            "158             0          0                                       0   \n",
            "159             0          0                                       1   \n",
            "160             0          0                                       0   \n",
            "161             0          0                                       0   \n",
            "\n",
            "     Mycobacterium_tuberculosis_Rv1258c_1_S292L  \\\n",
            "0                                             0   \n",
            "1                                             0   \n",
            "2                                             1   \n",
            "3                                             1   \n",
            "4                                             1   \n",
            "..                                          ...   \n",
            "157                                           1   \n",
            "158                                           1   \n",
            "159                                           0   \n",
            "160                                           1   \n",
            "161                                           1   \n",
            "\n",
            "     Mycobacterium_tuberculosis_Rv1258c_1_V219A  \\\n",
            "0                                             0   \n",
            "1                                             0   \n",
            "2                                             1   \n",
            "3                                             1   \n",
            "4                                             1   \n",
            "..                                          ...   \n",
            "157                                           1   \n",
            "158                                           1   \n",
            "159                                           0   \n",
            "160                                           1   \n",
            "161                                           1   \n",
            "\n",
            "     Mycobacterium_tuberculosis_ndh_.  Mycobacterium_tuberculosis_ndh_A300P  \\\n",
            "0                                   0                                     1   \n",
            "1                                   0                                     1   \n",
            "2                                   0                                     1   \n",
            "3                                   1                                     0   \n",
            "4                                   1                                     1   \n",
            "..                                ...                                   ...   \n",
            "157                                 0                                     1   \n",
            "158                                 0                                     1   \n",
            "159                                 0                                     1   \n",
            "160                                 0                                     1   \n",
            "161                                 0                                     1   \n",
            "\n",
            "     Mycobacterium_tuberculosis_ndh_G313R  \\\n",
            "0                                       1   \n",
            "1                                       1   \n",
            "2                                       1   \n",
            "3                                       0   \n",
            "4                                       1   \n",
            "..                                    ...   \n",
            "157                                     1   \n",
            "158                                     1   \n",
            "159                                     1   \n",
            "160                                     1   \n",
            "161                                     1   \n",
            "\n",
            "     Mycobacterium_tuberculosis_ndh_G339A  \\\n",
            "0                                       1   \n",
            "1                                       1   \n",
            "2                                       1   \n",
            "3                                       0   \n",
            "4                                       1   \n",
            "..                                    ...   \n",
            "157                                     1   \n",
            "158                                     1   \n",
            "159                                     1   \n",
            "160                                     1   \n",
            "161                                     1   \n",
            "\n",
            "     Mycobacterium_tuberculosis_ndh_L50V  ...  tlyA_A91E  tlyA_E238K  \\\n",
            "0                                      1  ...          1           1   \n",
            "1                                      1  ...          1           1   \n",
            "2                                      1  ...          1           1   \n",
            "3                                      1  ...          1           1   \n",
            "4                                      1  ...          1           1   \n",
            "..                                   ...  ...        ...         ...   \n",
            "157                                    1  ...          1           1   \n",
            "158                                    1  ...          1           1   \n",
            "159                                    1  ...          1           1   \n",
            "160                                    1  ...          1           1   \n",
            "161                                    1  ...          1           1   \n",
            "\n",
            "     tlyA_F185L  tlyA_K69E  tlyA_L118P  tlyA_L150P  tlyA_N236K  tlyA_P183L  \\\n",
            "0             1          1           1           1           1           1   \n",
            "1             1          1           1           1           1           1   \n",
            "2             1          1           1           1           1           1   \n",
            "3             1          1           1           1           1           1   \n",
            "4             1          1           1           1           1           1   \n",
            "..          ...        ...         ...         ...         ...         ...   \n",
            "157           1          1           1           1           1           1   \n",
            "158           1          1           1           1           1           1   \n",
            "159           1          1           1           1           1           1   \n",
            "160           1          1           1           1           1           1   \n",
            "161           1          1           1           1           1           1   \n",
            "\n",
            "     tlyA_R14W  tlyA_V128E  \n",
            "0            1           1  \n",
            "1            1           1  \n",
            "2            1           1  \n",
            "3            1           1  \n",
            "4            1           1  \n",
            "..         ...         ...  \n",
            "157          1           1  \n",
            "158          1           1  \n",
            "159          1           1  \n",
            "160          1           1  \n",
            "161          1           1  \n",
            "\n",
            "[162 rows x 433 columns]      phen_inh  phen_rif  phen_pza  phen_emb\n",
            "0           1         1         0         1\n",
            "1           1         1         1         1\n",
            "2           1         1         0         1\n",
            "3           1         1         1         1\n",
            "4           1         1         1         1\n",
            "..        ...       ...       ...       ...\n",
            "157         1         0         0         1\n",
            "158         1         0         0         1\n",
            "159         1         0         1         1\n",
            "160         1         0         1         1\n",
            "161         1         0         0         1\n",
            "\n",
            "[162 rows x 4 columns] \n",
            "-------------------------------\n",
            "\n",
            "     AAC_2___Ic_.  Erm_37__.  Mycobacterium_tuberculosis_Rv1258c_1_.  \\\n",
            "0               0          0                                       1   \n",
            "1               0          0                                       1   \n",
            "2               0          0                                       0   \n",
            "3               0          0                                       0   \n",
            "4               0          0                                       0   \n",
            "..            ...        ...                                     ...   \n",
            "157             0          0                                       1   \n",
            "158             0          0                                       1   \n",
            "159             0          0                                       1   \n",
            "160             0          0                                       0   \n",
            "161             0          0                                       1   \n",
            "\n",
            "     Mycobacterium_tuberculosis_Rv1258c_1_S292L  \\\n",
            "0                                             0   \n",
            "1                                             0   \n",
            "2                                             1   \n",
            "3                                             1   \n",
            "4                                             1   \n",
            "..                                          ...   \n",
            "157                                           0   \n",
            "158                                           0   \n",
            "159                                           0   \n",
            "160                                           1   \n",
            "161                                           0   \n",
            "\n",
            "     Mycobacterium_tuberculosis_Rv1258c_1_V219A  \\\n",
            "0                                             0   \n",
            "1                                             0   \n",
            "2                                             1   \n",
            "3                                             1   \n",
            "4                                             1   \n",
            "..                                          ...   \n",
            "157                                           0   \n",
            "158                                           0   \n",
            "159                                           0   \n",
            "160                                           1   \n",
            "161                                           0   \n",
            "\n",
            "     Mycobacterium_tuberculosis_ndh_.  Mycobacterium_tuberculosis_ndh_A300P  \\\n",
            "0                                   0                                     1   \n",
            "1                                   0                                     1   \n",
            "2                                   0                                     1   \n",
            "3                                   1                                     0   \n",
            "4                                   1                                     1   \n",
            "..                                ...                                   ...   \n",
            "157                                 0                                     1   \n",
            "158                                 0                                     1   \n",
            "159                                 0                                     1   \n",
            "160                                 0                                     1   \n",
            "161                                 0                                     1   \n",
            "\n",
            "     Mycobacterium_tuberculosis_ndh_G313R  \\\n",
            "0                                       1   \n",
            "1                                       1   \n",
            "2                                       1   \n",
            "3                                       0   \n",
            "4                                       1   \n",
            "..                                    ...   \n",
            "157                                     1   \n",
            "158                                     1   \n",
            "159                                     1   \n",
            "160                                     1   \n",
            "161                                     1   \n",
            "\n",
            "     Mycobacterium_tuberculosis_ndh_G339A  \\\n",
            "0                                       1   \n",
            "1                                       1   \n",
            "2                                       1   \n",
            "3                                       0   \n",
            "4                                       1   \n",
            "..                                    ...   \n",
            "157                                     1   \n",
            "158                                     1   \n",
            "159                                     1   \n",
            "160                                     1   \n",
            "161                                     1   \n",
            "\n",
            "     Mycobacterium_tuberculosis_ndh_L50V  ...  tlyA_A91E  tlyA_E238K  \\\n",
            "0                                      1  ...          0           0   \n",
            "1                                      1  ...          0           0   \n",
            "2                                      1  ...          0           0   \n",
            "3                                      1  ...          0           0   \n",
            "4                                      1  ...          0           0   \n",
            "..                                   ...  ...        ...         ...   \n",
            "157                                    1  ...          0           0   \n",
            "158                                    1  ...          0           0   \n",
            "159                                    1  ...          0           0   \n",
            "160                                    1  ...          0           0   \n",
            "161                                    1  ...          0           0   \n",
            "\n",
            "     tlyA_F185L  tlyA_K69E  tlyA_L118P  tlyA_L150P  tlyA_N236K  tlyA_P183L  \\\n",
            "0             0          0           0           0           0           0   \n",
            "1             0          0           0           0           0           0   \n",
            "2             0          0           0           0           0           0   \n",
            "3             0          0           0           0           0           0   \n",
            "4             0          0           0           0           0           0   \n",
            "..          ...        ...         ...         ...         ...         ...   \n",
            "157           0          0           0           0           0           0   \n",
            "158           0          0           0           0           0           0   \n",
            "159           0          0           0           0           0           0   \n",
            "160           0          0           0           0           0           0   \n",
            "161           0          0           0           0           0           0   \n",
            "\n",
            "     tlyA_R14W  tlyA_V128E  \n",
            "0            1           0  \n",
            "1            1           0  \n",
            "2            1           0  \n",
            "3            1           0  \n",
            "4            1           0  \n",
            "..         ...         ...  \n",
            "157          1           0  \n",
            "158          1           0  \n",
            "159          1           0  \n",
            "160          1           0  \n",
            "161          1           0  \n",
            "\n",
            "[162 rows x 433 columns] 0      1\n",
            "1      1\n",
            "2      1\n",
            "3      1\n",
            "4      1\n",
            "      ..\n",
            "157    1\n",
            "158    1\n",
            "159    1\n",
            "160    1\n",
            "161    1\n",
            "Name: phen_emb, Length: 162, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    dataFrame = pd.read_csv(f'amr_datasets_r_emb.csv',sep=\",\")\n",
        "    dataFrame = dataFrame.drop('!accession', axis=1)\n",
        "    dataFrame = dataFrame.drop('line_age',axis=1)\n",
        "    dataFrame = dataFrame.drop('phen_r_emb',axis=1)\n",
        "\n",
        "    dataFrame2 = pd.read_csv(f'amr_datasets_classes_bin.csv',sep=\",\")\n",
        "    dataFrame2 = dataFrame2.drop('!accession', axis=1)\n",
        "    dataFrame2 = dataFrame2.drop('line_age',axis=1)\n",
        "\n",
        "    # dataFrame = pd.DataFrame({\n",
        "    #     \"Outlook\":\n",
        "    #     [\"S\",\"S\",\"O\",\"R\",\"R\",\"R\",\"O\",\"S\",\"S\",\"R\",\"S\",\"O\",\"O\",\"R\"],\n",
        "    #     \"Temp\": \n",
        "    #     [\"H\",\"H\",\"H\",\"M\",\"C\",\"C\",\"C\",\"M\",\"C\",\"M\",\"M\",\"M\",\"H\",\"M\"],\n",
        "    #     \"Humidity\": \n",
        "    #     [\"H\",\"H\",\"H\",\"H\",\"N\",\"N\",\"N\",\"H\",\"N\",\"N\",\"N\",\"H\",\"N\",\"H\"],\n",
        "    #     \"Windy\":\n",
        "    #     [\"F\",\"T\",\"F\",\"F\",\"F\",\"T\",\"T\",\"F\",\"F\",\"F\",\"T\",\"T\",\"F\",\"T\"],\n",
        "    #     \"Play\":\n",
        "    #     [\"F\",\"F\",\"T\",\"T\",\"T\",\"F\",\"T\",\"F\",\"T\",\"T\",\"T\",\"T\",\"T\",\"F\"]\n",
        "    # })\n",
        "\n",
        "    # create LabelEncoder object\n",
        "    label_encoder = LabelEncoder()\n",
        "\n",
        "    # fit and transform the categorical variable\n",
        "\n",
        "    # for header in column_headers:\n",
        "    for header in dataFrame.columns:\n",
        "      dataFrame[header] = label_encoder.fit_transform(dataFrame[header])\n",
        "\n",
        "    x_multilabel, y_multilabel = dataFrame2.iloc[:, :-4], dataFrame2.iloc[:, -4:] #multilabel\n",
        "    x_singlelabel, y_singlelabel = dataFrame.iloc[:, :-1], dataFrame.iloc[:, -1]  #singlelabel\n",
        "\n",
        "    print(x_multilabel,y_multilabel,\"\\n-------------------------------\\n\")\n",
        "    print(x_singlelabel,y_singlelabel)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entropy Calculation"
      ],
      "metadata": {
        "id": "D9fuiMEvoQaA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Marginal entropy"
      ],
      "metadata": {
        "id": "-4N7LiqHzQZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_marginal_ent(y):\n",
        "  mgn_entropys = []\n",
        "  for class_header in y.columns:\n",
        "    y_label = y[class_header].value_counts()\n",
        "    mgn_entropy = 0\n",
        "    for idx in range(len(y_label)):\n",
        "      prob = y_label[idx]/len(y)\n",
        "      mgn_entropy += (prob * math.log2(prob))\n",
        "    mgn_entropys.append(-1*mgn_entropy)\n",
        "    print(f\"marginal entropy {class_header}: {mgn_entropy}\\n\")\n",
        "  return mgn_entropys"
      ],
      "metadata": {
        "id": "8FG6wJ6G4KbH"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conditional entropy"
      ],
      "metadata": {
        "id": "cPYO5qDl4HMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_conditional_entropy(x,y):\n",
        "\n",
        "  cond_entropys = []\n",
        "  attrs = x.columns\n",
        "  class_label_name = y.name\n",
        "\n",
        "  for attr in attrs:\n",
        "    \n",
        "    # count all unique value of an attribute\n",
        "    attr_vals = x[attr].value_counts()\n",
        "    cond_entropy = 0\n",
        "\n",
        "    for attr_val in range(len(attr_vals)):\n",
        "\n",
        "      # print attribute name and the selected value \n",
        "      # print(attr, attr_val)\n",
        "\n",
        "      # get index of specific attribute value e.g idx of (Outlook == Sunny)\n",
        "      val_idx = x[x[attr]==attr_val].index\n",
        "      # print(val_idx)\n",
        "\n",
        "      # total count of instance with specific attribute value\n",
        "      val_cnt = len(val_idx)\n",
        "      val_prob = -1*val_cnt/len(y)\n",
        "\n",
        "      # get information of class label based on specific attr value idx\n",
        "      val_labels = y[val_idx].value_counts()\n",
        "      # print(val_labels)\n",
        "      tmp = 0\n",
        "\n",
        "      for val_label_idx, val_label in enumerate(val_labels):\n",
        "        if (val_label == val_cnt):\n",
        "          tmp += 0\n",
        "        else :\n",
        "          val_label_prob = val_label/val_cnt \n",
        "          tmp += (val_label_prob* math.log2(val_label_prob))\n",
        "\n",
        "        # count total label for each attr value\n",
        "        # print(f\"label {val_label_idx} count\" \\\n",
        "        #   f\" in attr {attr}-{attr_val} : {val_label}\"\n",
        "        # )\n",
        "        \n",
        "      cond_entropy += val_prob * tmp\n",
        "      # print(f\"{val_prob * tmp}\\n\")\n",
        "\n",
        "    print(f\"conditional entropy for {class_label_name}|{attr}:\",cond_entropy)\n",
        "    print(\"\\n\")\n",
        "    cond_entropys.append(cond_entropy)\n",
        "\n",
        "  print(cond_entropys)\n",
        "  return cond_entropys"
      ],
      "metadata": {
        "id": "pCwHNp214JVS"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1Rhh13ASLSS"
      },
      "source": [
        "# Code below for multiple label dataset (can be multiple value in single label) with joint information gain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get Joint Information Gain"
      ],
      "metadata": {
        "id": "OJYdnErx6rDr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ohfu4t2Rgaw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "outputId": "5fd4288c-d265-43bf-8497-ce8f8ba8ab1c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-8d57de658f5c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get marginal entropy for each class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmgn_entropys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_marginal_ent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mjoint_cond_entropys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Get conditional entropy for each class label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-87-a1dafdd8465c>\u001b[0m in \u001b[0;36mget_marginal_ent\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_marginal_ent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mmgn_entropys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mclass_header\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0my_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_header\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmgn_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5900\u001b[0m         ):\n\u001b[1;32m   5901\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5902\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5904\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'columns'"
          ]
        }
      ],
      "source": [
        "# Get marginal entropy for each class\n",
        "mgn_entropys = get_marginal_ent(y)\n",
        "\n",
        "joint_cond_entropys = []\n",
        "# Get conditional entropy for each class label\n",
        "for class_header_idx,class_header in enumerate(y.columns):\n",
        "  #y_label = y[class_header].value_counts()\n",
        "  y_label = y[class_header]\n",
        "  joint_cond_entropys.append(get_conditional_entropy(x,y_label))\n",
        "\n",
        "# Get Joint Information gain for all attribute/feature\n",
        "joint_information_gains = []\n",
        "for cond_idx, cond_entropys in enumerate(joint_cond_entropys[0]):\n",
        "  joint_information_gain = 0\n",
        "  for mgn_idx,mgn_entropy in enumerate(mgn_entropys):\n",
        "    joint_information_gain += mgn_entropy-joint_cond_entropys[mgn_idx][cond_idx]\n",
        "  joint_information_gains.append(joint_information_gain)\n",
        "np_joint_information_gains = np.array(joint_information_gains)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"all class marginal entropy:\\n\",len(mgn_entropys),mgn_entropys)\n",
        "print(\"all class conditional entropy:\\n\",np.array(joint_cond_entropys).shape)\n",
        "print(joint_cond_entropys)\n",
        "print(\"joint ig for all attr:\\n\",np.array(joint_information_gains))\n",
        "print(\"max joint ig on attribute\\n\",\n",
        "      x.columns[np_joint_information_gains.argmax()], \"\\nwith joint ig value:\",\n",
        "      np_joint_information_gains[np_joint_information_gains.argmax()]\n",
        "      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "PyQj5SIf-HQY",
        "outputId": "783522de-d984-45aa-f7a6-e6c6bca2eeaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all class marginal entropy:\n",
            " 5 [1.5774062828523454, 1.5566567074628228, 1.0, 0.9852281360342515, 0.9402859586706311]\n",
            "all class conditional entropy:\n",
            " (5, 0)\n",
            "[[], [], [], [], []]\n",
            "joint ig for all attr:\n",
            " []\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-2659aa5339a5>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"joint ig for all attr:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoint_information_gains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m print(\"max joint ig on attribute\\n\",\n\u001b[0;32m----> 6\u001b[0;31m       \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp_joint_information_gains\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\nwith joint ig value:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m       \u001b[0mnp_joint_information_gains\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp_joint_information_gains\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       )\n",
            "\u001b[0;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sxzbrFbSDWD"
      },
      "source": [
        "# Code below for single label dataset (can be multiple value in single label) with information gain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmoDm31eCYF7"
      },
      "outputs": [],
      "source": [
        "print(y.value_counts())\n",
        "print(len(y))\n",
        "mgn_entropy = 0\n",
        "cond_entropys = []\n",
        "for idx in range(len(y.value_counts())):\n",
        "  prob = y.value_counts()[idx]/len(y)\n",
        "  print(prob * math.log2(prob))\n",
        "  mgn_entropy += (prob * math.log2(prob))\n",
        "\n",
        "print(\"marginal entropy: \"+str(-1*mgn_entropy),\"\\n\")\n",
        "\n",
        "# print(x.Outlook.value_counts())\n",
        "# print(x[x.columns[0]])\n",
        "\n",
        "# count number of column in feature spaces\n",
        "attrs = x.columns\n",
        "for attr in range(len(attrs)):\n",
        "\n",
        "  # count all unique value of an attribute\n",
        "  attr_vals = x[x.columns[attr]].value_counts()\n",
        "  cond_entropy = 0\n",
        "\n",
        "  for attr_val in range(len(attr_vals)):\n",
        "    \n",
        "    # print attribute name and the selected value \n",
        "    print(x.columns[attr], attr_val)\n",
        "\n",
        "    # get index of specific attribute value e.g idx of (Outlook == Sunny)\n",
        "    val_idx = x[x[x.columns[attr]]==attr_val].index\n",
        "    print(val_idx)\n",
        "\n",
        "    # total count of instance with specific attribute value\n",
        "    val_cnt = len(val_idx)\n",
        "    val_prob = -1*val_cnt/len(y)\n",
        "\n",
        "    # get information of class label based on specific attr value idx\n",
        "    val_labels = y[val_idx].value_counts()\n",
        "    print(val_labels)\n",
        "    tmp = 0\n",
        "\n",
        "    for val_label_idx, val_label in enumerate(val_labels):\n",
        "      if (val_label == val_cnt):\n",
        "        tmp += 0\n",
        "      else :\n",
        "        val_label_prob = val_label/val_cnt \n",
        "        tmp += (val_label_prob* math.log2(val_label_prob))\n",
        "\n",
        "      # count total label for each attr value\n",
        "      print(f\"label {val_label_idx} count\" \\\n",
        "        f\" in attr {x.columns[attr]}-{attr_val} : {val_label}\"\n",
        "      )\n",
        "    cond_entropy += val_prob * tmp\n",
        "    print(f\"{val_prob * tmp}\\n\")\n",
        "\n",
        "  print(f\"conditional entropy for Class|{x.columns[attr]}:\",cond_entropy)\n",
        "  print(\"\\n\")\n",
        "  cond_entropys.append(cond_entropy)\n",
        "\n",
        "print(cond_entropys)\n",
        "\n",
        "for cond_entropy in cond_entropys:\n",
        "  print(-1*mgn_entropy-cond_entropy)\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipEma7srJFAk"
      },
      "source": [
        "# RF Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "mvFzcXT4EQrV"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "@Env: Python2.7\n",
        "@Time: 2019/10/24 13:31\n",
        "@Author: zhaoxingfeng\n",
        "@Function：Random Forest（RF），随机森林二分类\n",
        "@Version: V1.2\n",
        "参考文献：\n",
        "[1] UCI. wine[DB/OL].https://archive.ics.uci.edu/ml/machine-learning-databases/wine.\n",
        "\"\"\"\n",
        "\n",
        "class Tree(object):\n",
        "    \"\"\"Define a decision tree\"\"\"\n",
        "    def __init__(self):\n",
        "        self.split_feature = None\n",
        "        self.split_value = None\n",
        "        self.leaf_value = None\n",
        "        self.tree_left = None\n",
        "        self.tree_right = None\n",
        "\n",
        "    def calc_predict_value(self, dataset):\n",
        "        \"\"\"Find the leaf node of the sample through the recursive decision tree\"\"\"\n",
        "        if self.leaf_value is not None:\n",
        "            return self.leaf_value\n",
        "        elif dataset[self.split_feature] <= self.split_value:\n",
        "            return self.tree_left.calc_predict_value(dataset)\n",
        "        else:\n",
        "            return self.tree_right.calc_predict_value(dataset)\n",
        "\n",
        "    def describe_tree(self):\n",
        "        \"\"\"\n",
        "        Print the decision tree in json form, \n",
        "        which is convenient for viewing the tree structure\n",
        "        \"\"\"\n",
        "        if not self.tree_left and not self.tree_right:\n",
        "            leaf_info = \"{leaf_value:\" + str(self.leaf_value) + \"}\"\n",
        "            return leaf_info\n",
        "        left_info = self.tree_left.describe_tree()\n",
        "        right_info = self.tree_right.describe_tree()\n",
        "        tree_structure = \"{split_feature:\" + str(self.split_feature) + \\\n",
        "                         \",split_value:\" + str(self.split_value) + \\\n",
        "                         \",left_tree:\" + left_info + \\\n",
        "                         \",right_tree:\" + right_info + \"}\"\n",
        "        return tree_structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "0SQjkSjvEU1d"
      },
      "outputs": [],
      "source": [
        "class RandomForestClassifier(object):\n",
        "    def __init__(self, n_estimators=10, max_depth=-1, min_samples_split=2, min_samples_leaf=1,\n",
        "                 min_split_gain=0.0, colsample_bytree=None, subsample=0.8, random_state=None,\n",
        "                 classifier_type=\"gini\", multilabel=False):\n",
        "        \"\"\"\n",
        "        Random Forest Parameters\n",
        "         ----------\n",
        "         n_estimators: \n",
        "              number of trees\n",
        "         max_depth: \n",
        "              tree depth, -1 means unlimited depth\n",
        "         min_samples_split: \n",
        "              The minimum number of samples required for node splitting, \n",
        "              the node terminates splitting if it is less than this value\n",
        "         min_samples_leaf: \n",
        "              The minimum sample number of leaf nodes, \n",
        "              less than this value leaves are merged\n",
        "         min_split_gain: \n",
        "              The minimum gain required for splitting, \n",
        "              less than this value the node terminates the split\n",
        "         colsample_bytree: \n",
        "              Column sampling setting, which can be [sqrt, log2]. \n",
        "              sqrt means randomly selecting sqrt(n_features) features,\n",
        "              log2 means to randomly select log(n_features) features, \n",
        "              if set to other, column sampling will not be performed\n",
        "         subsample: \n",
        "              line sampling ratio\n",
        "         random_state: \n",
        "              Random seed, after setting, \n",
        "              the n_estimators sample sets generated each time will not change, \n",
        "              ensuring that the experiment can be repeated\n",
        "         classifier_type:\n",
        "              Select method for node splitting \"gini\" or \"information_gain\"\n",
        "        \"\"\"\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_depth = max_depth if max_depth != -1 else float('inf')\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.min_split_gain = min_split_gain\n",
        "        self.colsample_bytree = colsample_bytree\n",
        "        self.subsample = subsample\n",
        "        self.random_state = random_state\n",
        "        self.trees = None\n",
        "        self.feature_importances_ = dict()\n",
        "        self.classifier_type = classifier_type\n",
        "        self.multilabel = multilabel\n",
        "\n",
        "    def fit(self, dataset, targets):\n",
        "        \"\"\"Model training entry\"\"\"\n",
        "        #Check if the targets is 1D Array (Series data type)\n",
        "        #and convert into dataframe type\n",
        "        if type(targets)==pd.core.series.Series:\n",
        "          assert targets.unique().__len__() >= 2, \"There must be two class for targets!\"\n",
        "          targets = targets.to_frame()\n",
        "\n",
        "        if self.random_state:\n",
        "            random.seed(self.random_state)\n",
        "        random_state_stages = random.sample(range(self.n_estimators), self.n_estimators)\n",
        "\n",
        "        # Two column sampling methods\n",
        "        if self.colsample_bytree == \"sqrt\":\n",
        "            self.colsample_bytree = int(len(dataset.columns) ** 0.5)\n",
        "        elif self.colsample_bytree == \"log2\":\n",
        "            self.colsample_bytree = int(math.log(len(dataset.columns)))\n",
        "        else:\n",
        "            self.colsample_bytree = len(dataset.columns)\n",
        "\n",
        "        # Build multiple decision trees in parallel\n",
        "        self.trees = Parallel(n_jobs=-1, verbose=0, backend=\"threading\")(\n",
        "            delayed(self._parallel_build_trees)(dataset, targets, random_state)\n",
        "                for random_state in random_state_stages)\n",
        "        \n",
        "    def _parallel_build_trees(self, dataset, targets, random_state):\n",
        "        \"\"\"\n",
        "        bootstrap has put back sampling to \n",
        "        generate a training sample set and build a decision tree\n",
        "        \"\"\"\n",
        "        subcol_index = random.sample(dataset.columns.tolist(), self.colsample_bytree)\n",
        "        dataset_stage = dataset.sample(n=int(self.subsample * len(dataset)), replace=True, \n",
        "                                        random_state=random_state).reset_index(drop=True)\n",
        "        dataset_stage = dataset_stage.loc[:, subcol_index]\n",
        "        targets_stage = targets.sample(n=int(self.subsample * len(dataset)), replace=True, \n",
        "                                        random_state=random_state).reset_index(drop=True)\n",
        "        tree = self._build_single_tree(dataset_stage, targets_stage, depth=0)\n",
        "\n",
        "        # -------------- PRINT BEST NODE --------------\n",
        "        # print(tree.describe_tree())\n",
        "\n",
        "        return tree\n",
        "\n",
        "    def _build_single_tree(self, dataset, targets, depth):\n",
        "        \"\"\"Recursively build a decision tree\"\"\"\n",
        "        # If the categories of the node \n",
        "        # are all the same/the samples are less than \n",
        "        # the minimum number of samples required for splitting, \n",
        "        # select the category with the most occurrences. \n",
        "        # Termination of division/split\n",
        "        if targets.shape[1]==1:\n",
        "          if targets.shape[1]==1 and \\\n",
        "          ( len(targets[targets.columns[0]].unique()) <= 1 or \n",
        "           dataset.__len__() <= self.min_samples_split ):\n",
        "              tree = Tree()\n",
        "              # tree.leaf_value = self.calc_leaf_value(targets[targets.columns[0]],self.multilabel)\n",
        "              tree.leaf_value = self.calc_leaf_value(targets,self.multilabel)\n",
        "              return tree\n",
        "\n",
        "        if depth < self.max_depth:\n",
        "            best_split_feature, best_split_value, best_split_gain = self.choose_best_feature(dataset, targets)\n",
        "            left_dataset, right_dataset, left_targets, right_targets = \\\n",
        "                self.split_dataset(dataset, targets, best_split_feature, best_split_value)\n",
        "\n",
        "            tree = Tree()\n",
        "            # If after the parent node is split, \n",
        "            # the left leaf node/right leaf node sample is less than \n",
        "            # the set minimum number of leaf node samples, \n",
        "            # the parent node will terminate the split\n",
        "            if left_dataset.__len__() <= self.min_samples_leaf or \\\n",
        "                    right_dataset.__len__() <= self.min_samples_leaf or \\\n",
        "                    best_split_gain <= self.min_split_gain:\n",
        "                # tree.leaf_value = self.calc_leaf_value(targets[targets.columns[0]],self.multilabel)\n",
        "                tree.leaf_value = self.calc_leaf_value(targets,self.multilabel)\n",
        "                return tree\n",
        "            else:\n",
        "                # If this feature is used when splitting, \n",
        "                # the importance of this feature will be increased by 1\n",
        "                self.feature_importances_[best_split_feature] = \\\n",
        "                    self.feature_importances_.get(best_split_feature, 0) + 1\n",
        "\n",
        "                tree.split_feature = best_split_feature\n",
        "                tree.split_value = best_split_value\n",
        "                tree.tree_left = self._build_single_tree(left_dataset, left_targets, depth+1)\n",
        "                tree.tree_right = self._build_single_tree(right_dataset, right_targets, depth+1)\n",
        "                return tree\n",
        "        # If the depth of the tree exceeds the preset value, terminate the split\n",
        "        else:\n",
        "            tree = Tree()\n",
        "            # tree.leaf_value = self.calc_leaf_value(targets[targets.columns[0]],self.multilabel)\n",
        "            tree.leaf_value = self.calc_leaf_value(targets,self.multilabel)\n",
        "            return tree\n",
        "\n",
        "    def choose_best_feature(self, dataset, targets):\n",
        "        \"\"\"\n",
        "        Find the best data set division method, \n",
        "        find the optimal split feature, \n",
        "        split threshold, split gain\n",
        "        \"\"\"\n",
        "        best_split_gain = 1\n",
        "        best_split_feature = None\n",
        "        best_split_value = None\n",
        "\n",
        "        if self.classifier_type == \"gini\":\n",
        "            for feature in dataset.columns:\n",
        "                if dataset[feature].unique().__len__() <= 100:\n",
        "                    unique_values = sorted(dataset[feature].unique().tolist())\n",
        "                # If the dimension feature has too many values, \n",
        "                # select the 100th percentile value as the split threshold to be selected\n",
        "                else:\n",
        "                    unique_values = np.unique([np.percentile(dataset[feature], x)\n",
        "                                              for x in np.linspace(0, 100, 100)]\n",
        "                                              )\n",
        "\n",
        "                # Calculate the splitting gain for the possible splitting thresholds, \n",
        "                # and select the threshold with the largest gain\n",
        "                for split_value in unique_values:\n",
        "                    # get subset of targets that <= split value into left_targets\n",
        "                    left_targets = targets[dataset[feature] <= split_value]\n",
        "                    # get subset of targets that > split value into right_targets\n",
        "                    right_targets = targets[dataset[feature] > split_value]\n",
        "                    split_gain = self.calc_gini(left_targets[targets.columns[0]], right_targets[targets.columns[0]])\n",
        "\n",
        "                    if split_gain < best_split_gain:\n",
        "                        best_split_feature = feature\n",
        "                        best_split_value = split_value\n",
        "                        best_split_gain = split_gain\n",
        "                        \n",
        "        #################\n",
        "        #      FIX      #\n",
        "        #     JOINT     #\n",
        "        #   INFO_GAIN   #\n",
        "        #    DIBAWAH    #     \n",
        "        #################           \n",
        "        else : \n",
        "            # Get marginal entropy for each class\n",
        "            mgn_entropys = self.get_marginal_ent(targets)\n",
        "\n",
        "            joint_cond_entropys = []\n",
        "\n",
        "            # Get conditional entropy for each class label\n",
        "            for class_header_idx,class_header in enumerate(targets.columns):\n",
        "              #y_label = y[class_header].value_counts()\n",
        "              y_label = targets[class_header]\n",
        "              cond_entropys =\\\n",
        "                  self.get_conditional_entropy(dataset,y_label)\n",
        "              \n",
        "              joint_cond_entropys.append(\n",
        "                  cond_entropys\n",
        "              )\n",
        "            \n",
        "            # Get Joint Information gain for all attribute/feature\n",
        "            joint_information_gains = []\n",
        "            for cond_idx, cond_entropys in enumerate(joint_cond_entropys[0]):\n",
        "              joint_information_gain = 0\n",
        "              for mgn_idx,mgn_entropy in enumerate(mgn_entropys):\n",
        "                joint_information_gain += mgn_entropy-joint_cond_entropys[mgn_idx][cond_idx]\n",
        "              joint_information_gains.append(joint_information_gain)\n",
        "            \n",
        "            np_joint_information_gains = np.array(joint_information_gains)\n",
        "            best_split_feature = dataset.columns[\n",
        "                np.argmax(np_joint_information_gains)\n",
        "                ]\n",
        "            best_split_infogain = np_joint_information_gains.max()\n",
        "            best_split_value = 0\n",
        "\n",
        "        return best_split_feature, best_split_value, best_split_gain\n",
        "\n",
        "    @staticmethod\n",
        "    def calc_leaf_value(targets, multilabel):\n",
        "        \"\"\"\n",
        "        Select the category with the most occurrences \n",
        "        in the sample as the value of the leaf node\n",
        "        \"\"\"\n",
        "        # label_counts = collections.Counter(targets)\n",
        "        # major_label = max(zip(label_counts.values(), label_counts.keys()))\n",
        "        # print(\"major_label\",major_label)\n",
        "        # print(\"major_label[1]\",major_label[1])\n",
        "        # # return value dari resistance x (true/false)\n",
        "        # return major_label[1]\n",
        "\n",
        "\n",
        "        all_major_label = []\n",
        "        for target_label in targets:\n",
        "          label_counts = collections.Counter(targets[target_label])\n",
        "          major_label = max(zip(label_counts.values(), label_counts.keys()))\n",
        "          all_major_label.append(major_label)\n",
        "        # # return list value dari multilabel resistance (list(true/false))\n",
        "        return all_major_label\n",
        "\n",
        "    # Information Gain METHOD - Conditional Entropy\n",
        "    @staticmethod\n",
        "    def get_conditional_entropy(x,y):\n",
        "\n",
        "        cond_entropys = []\n",
        "        attrs = x.columns\n",
        "        class_label_name = y.name\n",
        "\n",
        "        for attr in attrs:\n",
        "          \n",
        "          # count all unique value of an attribute\n",
        "          attr_vals = x[attr].value_counts()\n",
        "          cond_entropy = []\n",
        "\n",
        "          for attr_val in range(len(attr_vals)):\n",
        "\n",
        "            # print attribute name and the selected value \n",
        "            # print(attr, attr_val)\n",
        "\n",
        "            # get index of specific attribute value e.g idx of (Outlook == Sunny)\n",
        "            val_idx = x[x[attr]==attr_val].index\n",
        "            # print(val_idx)\n",
        "\n",
        "            # total count of instance with specific attribute value\n",
        "            val_cnt = len(val_idx)\n",
        "            val_prob = -1*val_cnt/len(y)\n",
        "\n",
        "            # get information of class label based on specific attr value idx\n",
        "            val_labels = y[val_idx].value_counts()\n",
        "            # print(val_labels)\n",
        "            tmp = 0\n",
        "\n",
        "            for val_label_idx, val_label in enumerate(val_labels):\n",
        "              if (val_label == val_cnt):\n",
        "                tmp += 0\n",
        "              else :\n",
        "                val_label_prob = val_label/val_cnt \n",
        "                tmp += (val_label_prob* math.log2(val_label_prob))\n",
        "\n",
        "              # count total label for each attr value\n",
        "              # print(f\"label {val_label_idx} count\" \\\n",
        "              #   f\" in attr {attr}-{attr_val} : {val_label}\"\n",
        "              # )\n",
        "            \n",
        "            attr_val_ent = val_prob * tmp\n",
        "\n",
        "            cond_entropy.append(attr_val_ent) \n",
        "            # print(f\"{val_prob * tmp}\\n\")\n",
        "\n",
        "          #print(f\"conditional entropy for {class_label_name}|{attr}:\",np.sum(np.array(cond_entropy)))\n",
        "          #print(\"\\n\")\n",
        "          \n",
        "          cond_entropys.append(np.sum(np.array(cond_entropy)))\n",
        "\n",
        "        #print(cond_entropys)\n",
        "        return cond_entropys\n",
        "\n",
        "    # Information Gain METHOD - Marginal Entropy\n",
        "    @staticmethod\n",
        "    def get_marginal_ent(y):\n",
        "        mgn_entropys = []\n",
        "        for class_header in y.columns:\n",
        "          y_label = y[class_header].value_counts()\n",
        "          mgn_entropy = 0\n",
        "          for idx in range(len(y_label)):\n",
        "            prob = y_label[idx]/len(y)\n",
        "            mgn_entropy += (prob * math.log2(prob))\n",
        "          mgn_entropys.append(-1*mgn_entropy)\n",
        "          #print(f\"marginal entropy {class_header}: {mgn_entropy}\\n\")\n",
        "        return mgn_entropys\n",
        "\n",
        "    @staticmethod\n",
        "    def calc_gini(left_targets, right_targets):\n",
        "        \"\"\"\n",
        "        The classification tree uses the Gini index as an \n",
        "        indicator to select the optimal split point\n",
        "        \"\"\"\n",
        "        split_gain = 0\n",
        "        for targets in [left_targets, right_targets]:\n",
        "            gini = 1\n",
        "            # Count how many samples are in each category, \n",
        "            # and then calculate gini\n",
        "            label_counts = collections.Counter(targets)\n",
        "            for key in label_counts:\n",
        "                prob = label_counts[key] * 1.0 / len(targets)\n",
        "                gini -= prob ** 2\n",
        "            split_gain += len(targets) * 1.0 / (len(left_targets) + len(right_targets)) * gini\n",
        "        return split_gain\n",
        "\n",
        "    @staticmethod\n",
        "    def split_dataset(dataset, targets, split_feature, split_value):\n",
        "        \"\"\"\n",
        "        Divide the sample into left and right parts according to the \n",
        "        characteristics and threshold, the left is less than or \n",
        "        equal to the threshold, and the right is greater than the threshold\n",
        "        \"\"\"\n",
        "        left_dataset = dataset[dataset[split_feature] <= split_value]\n",
        "        left_targets = targets[dataset[split_feature] <= split_value]\n",
        "        right_dataset = dataset[dataset[split_feature] > split_value]\n",
        "        right_targets = targets[dataset[split_feature] > split_value]\n",
        "        return left_dataset, right_dataset, left_targets, right_targets\n",
        "\n",
        "    def predict(self, dataset,label_num=0):\n",
        "        \"\"\"Input sample, predict category\"\"\"\n",
        "        \n",
        "        res = []\n",
        "        for _, row in dataset.iterrows():\n",
        "            preds_list = []\n",
        "            # Count the prediction results of each tree, \n",
        "            # and select the result with the most occurrences \n",
        "            # as the final category\n",
        "            for tree in self.trees:\n",
        "                preds_list.append(tree.calc_predict_value(row))\n",
        "\n",
        "            preds_list = np.array(preds_list)\n",
        "            pred_list = preds_list[:,label_num]\n",
        "            separated_pred_label_unique, separated_pred_label_counts = np.unique(pred_list, return_counts=True)\n",
        "            pred_label = separated_pred_label_unique[\n",
        "                separated_pred_label_counts == separated_pred_label_counts.max()\n",
        "                ]\n",
        "            res.append(pred_label[0].item())\n",
        "\n",
        "        print(res)\n",
        "        return np.array(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBVAOaooJJX0"
      },
      "source": [
        "# Run here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearch Optimization"
      ],
      "metadata": {
        "id": "nRiC8jqZTQik"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "D32M1uEoEawV",
        "outputId": "e1f32c54-dce3-4230-bdd0-7319c6c7007e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------ SINGLELABEL phen_emb w param 5,10,2,10 ------\n",
            "\n",
            "RESISTANCE FOR LABEL phen_emb with parameter 5,10,2,10\n",
            "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "0.7355371900826446\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "0.6585365853658537\n",
            "{'ethA_2_.': 1, 'Planobispora_rosea_EF_Tu_.': 1, 'pncA_A102V': 1, 'pncA_W68G': 1} \n",
            "\n",
            "\n",
            "-------- MULTILABEL w param 5,10,2,10 --------\n",
            "\n",
            "RESISTANCE FOR LABEL phen_inh with parameter 5,10,2,10\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "0.6528925619834711\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "0.6829268292682927\n",
            "RESISTANCE FOR LABEL phen_rif with parameter 5,10,2,10\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "0.8429752066115702\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "0.8048780487804879\n",
            "RESISTANCE FOR LABEL phen_pza with parameter 5,10,2,10\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "0.9338842975206612\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "0.8780487804878049\n",
            "RESISTANCE FOR LABEL phen_emb with parameter 5,10,2,10\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "0.7024793388429752\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "0.7073170731707317\n",
            "{} \n",
            "\n",
            "\n",
            "------ SINGLELABEL phen_emb w param 10,25,8,20 ------\n",
            "\n",
            "RESISTANCE FOR LABEL phen_emb with parameter 10,25,8,20\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "0.7107438016528925\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "0.7073170731707317\n",
            "{'katG_1_S315N': 2, 'pncA_W68L': 1, 'pncA_F58L': 1, 'embA_.': 2, 'iniA_.': 2, 'mshA_1_.': 1, 'pncA_Q141P': 2, 'ethA_2_C403Y': 1, 'embB_1_Y334H': 1, 'Mycobacterium_tuberculosis_ndh_A300P': 1, 'gidB_.': 1, 'iniB_.': 1, 'embB_1_G406A': 1, 'pncA_V45G': 1, 'Erm_37__.': 1, 'gidB_D67H': 1, 'rpoB_1_.': 1, 'embB_1_R469P': 1} \n",
            "\n",
            "\n",
            "-------- MULTILABEL w param 10,25,8,20 --------\n",
            "\n",
            "RESISTANCE FOR LABEL phen_inh with parameter 10,25,8,20\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "0.6694214876033058\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "0.6341463414634146\n",
            "RESISTANCE FOR LABEL phen_rif with parameter 10,25,8,20\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "0.8264462809917356\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "0.8536585365853658\n",
            "RESISTANCE FOR LABEL phen_pza with parameter 10,25,8,20\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "0.9256198347107438\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "0.9024390243902439\n",
            "RESISTANCE FOR LABEL phen_emb with parameter 10,25,8,20\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "0.7107438016528925\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "0.6829268292682927\n",
            "{} \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-171-b412740f0358>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m   )\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   \u001b[0mclf_singlelabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_single_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_single_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-168-b95fcf133323>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, targets)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Build multiple decision trees in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         self.trees = Parallel(n_jobs=-1, verbose=0, backend=\"threading\")(\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parallel_build_trees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 for random_state in random_state_stages)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "opt_n_estimators = [5,10,25]\n",
        "opt_max_depth = [10,25,50]\n",
        "opt_random_state = [2,8,16]\n",
        "opt_min_samples_split = [10,20,30]\n",
        "\n",
        "arr_acc_train = []\n",
        "arr_acc_test = []\n",
        "\n",
        "for p1,p2,p3,p4 in zip(\n",
        "    opt_n_estimators, \n",
        "    opt_max_depth, \n",
        "    opt_random_state, \n",
        "    opt_min_samples_split\n",
        "    ):\n",
        "\n",
        "  clf_singlelabel = RandomForestClassifier(n_estimators=p1,\n",
        "                              max_depth=p2,\n",
        "                              min_samples_split=p4,\n",
        "                              min_samples_leaf=2,\n",
        "                              min_split_gain=0.0,\n",
        "                              colsample_bytree=\"sqrt\",\n",
        "                              subsample=0.8,\n",
        "                              random_state=p3,\n",
        "                              classifier_type=\"gini\",\n",
        "                              multilabel = False\n",
        "                              )\n",
        "  \n",
        "  x_single_train, x_single_test, y_single_train, y_single_test = train_test_split(\n",
        "      x_singlelabel, y_singlelabel, test_size=0.25, random_state=random.randint(1, 25)\n",
        "  )\n",
        "\n",
        "  clf_singlelabel.fit(x_single_train, y_single_train)\n",
        "\n",
        "  from sklearn import metrics\n",
        "  #SINGLE LABEL\n",
        "  print(f\"------ SINGLELABEL {label_name} w param {p1},{p2},{p3},{p4} ------\\n\")\n",
        "  for idx,label_name in enumerate(y_singlelabel.to_frame().columns):\n",
        "    print(f\"RESISTANCE FOR LABEL {label_name} with parameter {p1},{p2},{p3},{p4}\")\n",
        "    print(metrics.accuracy_score(y_single_train.to_frame()[label_name], \n",
        "                                 clf_singlelabel.predict(x_single_train,label_num=idx)\n",
        "                                 )\n",
        "    )\n",
        "    print(metrics.accuracy_score(y_single_test.to_frame()[label_name], \n",
        "                                 clf_singlelabel.predict(x_single_test,label_num=idx)\n",
        "                                 )\n",
        "    )\n",
        "  print(clf_singlelabel.feature_importances_,\"\\n\\n\")\n",
        "\n",
        "  #----------------- MULTILABEL -----------------\n",
        "  \n",
        "  clf_multilabel = RandomForestClassifier(n_estimators=p1,\n",
        "                              max_depth=p2,\n",
        "                              min_samples_split=p4,\n",
        "                              min_samples_leaf=2,\n",
        "                              min_split_gain=0.0,\n",
        "                              colsample_bytree=\"sqrt\",\n",
        "                              subsample=0.8,\n",
        "                              random_state=p3,\n",
        "                              classifier_type=\"information_gain\",\n",
        "                              multilabel = True\n",
        "                              )\n",
        "  \n",
        "  x_multi_train, x_multi_test, y_multi_train, y_multi_test = train_test_split(\n",
        "      x_multilabel, y_multilabel, test_size=0.25, random_state=random.randint(1, 25)\n",
        "  )\n",
        "\n",
        "  clf_multilabel.fit(x_multi_train, y_multi_train)\n",
        "  \n",
        "  #MULTI LABEL\n",
        "  print(f\"-------- MULTILABEL w param {p1},{p2},{p3},{p4} --------\\n\")\n",
        "  for idx,label_name in enumerate(y_multilabel.columns):\n",
        "    print(f\"RESISTANCE FOR LABEL {label_name} with parameter {p1},{p2},{p3},{p4}\")\n",
        "    print(metrics.accuracy_score(y_multi_train[label_name], \n",
        "                                 clf_multilabel.predict(x_multi_train,label_num=idx)\n",
        "                                 )\n",
        "    )\n",
        "    print(metrics.accuracy_score(y_multi_test[label_name], \n",
        "                                 clf_multilabel.predict(x_multi_test,label_num=idx)\n",
        "                                 )\n",
        "    )\n",
        "\n",
        "  print(clf_multilabel.feature_importances_,\"\\n\\n\")\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearch + KFOLD Optimization"
      ],
      "metadata": {
        "id": "HS-UWourTNaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt_n_estimators = [5,10,25]\n",
        "opt_max_depth = [10,25,50]\n",
        "opt_random_state = [2,8,16]\n",
        "opt_min_samples_split = [10,20,30]\n",
        "\n",
        "arr_acc_train = []\n",
        "arr_acc_test = []\n",
        "result_type_gsearch_kcv_test = []\n",
        "result_type_gsearch_kcv_train = []\n",
        "for p1,p2,p3,p4 in zip(\n",
        "    opt_n_estimators, \n",
        "    opt_max_depth, \n",
        "    opt_random_state, \n",
        "    opt_min_samples_split\n",
        "    ):\n",
        "\n",
        "    clf = RandomForestClassifier(n_estimators=p1,\n",
        "                                max_depth=p2,\n",
        "                                min_samples_split=p4,\n",
        "                                min_samples_leaf=2,\n",
        "                                min_split_gain=0.0,\n",
        "                                colsample_bytree=\"sqrt\",\n",
        "                                subsample=0.8,\n",
        "                                random_state=p3,\n",
        "                                classifier_type=\"information_gain\"\n",
        "                                )\n",
        "    \n",
        "    # x_train, x_test, y_train, y_test = train_test_split(\n",
        "    #     x, y, test_size=0.25, random_state=random.randint(1, 25)\n",
        "    # )\n",
        "\n",
        "    #---------K-Fold_Crossvalidation w SINGLELABEL EMB---------\n",
        "    kfold_cv = KFold(n_splits=5, random_state=67, shuffle=True)\n",
        "    fold_acc_train = []\n",
        "    fold_acc_test = []\n",
        "    for i, (train_index, test_index) in enumerate(kfold_cv.split(x_singlelabel)):\n",
        "        # print(f\"Fold {i}:\")\n",
        "        # print(f\"  Train idx={train_index}\")\n",
        "        # print(f\"  Test idx={test_index}\")\n",
        "        x_train , x_test = x_singlelabel.iloc[train_index,:],x_singlelabel.iloc[test_index,:]\n",
        "        y_train , y_test = y_singlelabel[train_index] , y_singlelabel[test_index]\n",
        "\n",
        "        clf.fit(x_train, y_train)\n",
        "\n",
        "        from sklearn import metrics\n",
        "        print(\"-------MODEL with Parameter:\",p1,p2,p3,p4,f\"FOLD-{i}-------\")\n",
        "        n_fold_gridsearch_train_acc = metrics.accuracy_score(y_train, clf.predict(x_train))\n",
        "        n_fold_gridsearch_test_acc = metrics.accuracy_score(y_test, clf.predict(x_test))\n",
        "        print(n_fold_gridsearch_train_acc)\n",
        "        print(n_fold_gridsearch_test_acc)\n",
        "\n",
        "        fold_acc_train.append(n_fold_gridsearch_train_acc)\n",
        "        fold_acc_test.append(n_fold_gridsearch_test_acc)\n",
        "\n",
        "    result_type_gsearch_kcv_train.append(np.average(np.array(fold_acc_train)))\n",
        "    result_type_gsearch_kcv_test.append(np.average(np.array(fold_acc_test)))\n",
        "\n",
        "print(result_type_gsearch_kcv_train)\n",
        "print(result_type_gsearch_kcv_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        },
        "id": "3y8CgHTUTM_N",
        "outputId": "a04a52e7-958c-4941-b288-2d01853cf038"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------MODEL with Parameter: 5 10 2 10 FOLD-0-------\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "0.7054263565891473\n",
            "0.696969696969697\n",
            "-------MODEL with Parameter: 5 10 2 10 FOLD-1-------\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "0.6976744186046512\n",
            "0.7272727272727273\n",
            "-------MODEL with Parameter: 5 10 2 10 FOLD-2-------\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "0.6846153846153846\n",
            "0.78125\n",
            "-------MODEL with Parameter: 5 10 2 10 FOLD-3-------\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "0.7076923076923077\n",
            "0.6875\n",
            "-------MODEL with Parameter: 5 10 2 10 FOLD-4-------\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "0.7230769230769231\n",
            "0.625\n",
            "-------MODEL with Parameter: 10 25 8 20 FOLD-0-------\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "0.7054263565891473\n",
            "0.696969696969697\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-170-91437f269d5f>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0my_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_singlelabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_singlelabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-168-b95fcf133323>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, targets)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Build multiple decision trees in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         self.trees = Parallel(n_jobs=-1, verbose=0, backend=\"threading\")(\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parallel_build_trees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 for random_state in random_state_stages)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "D9fuiMEvoQaA",
        "N1Rhh13ASLSS",
        "1sxzbrFbSDWD"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}